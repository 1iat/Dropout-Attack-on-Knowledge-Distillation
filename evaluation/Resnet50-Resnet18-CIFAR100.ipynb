{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04815f9b-ba5d-40ce-af37-4c1217ab1275",
   "metadata": {},
   "source": [
    "# Normal Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799f42a5-a009-4b4e-ac85-3159d245af1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab9d75d-de10-4fff-827f-ababa6dca020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../modules')\n",
    "from custom_dropout import DeterministicDropout\n",
    "#from new_distilation_model import TeacherNet, StudentNet\n",
    "from model_wrapper import NetWrapper\n",
    "from import_data import load_cifar100\n",
    "from misc import write_to_json\n",
    "from torch import nn, optim\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from os.path import exists\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "import os\n",
    "import json\n",
    "from torchvision.models import resnet50, resnet18\n",
    "from torch import nn\n",
    "from torchvision.datasets import CIFAR100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370d81b2-ef11-48d6-8836-b18ead7f7b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeacherNet(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        \"\"\"\n",
    "        ResNet50-based teacher model with customizable dropout.\n",
    "\n",
    "            Parameters:\n",
    "                dropout: The dropout to use in the model\n",
    "        \"\"\"\n",
    "        super(TeacherNet, self).__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Load the ResNet50 model\n",
    "        self.resnet = resnet50(weights='IMAGENET1K_V1')\n",
    "\n",
    "        # Modify the fully connected layer\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(self.resnet.fc.in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            \n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            \n",
    "            nn.Linear(256, 100)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        \"\"\"\n",
    "        Runs the forward pass through the teacher model.\n",
    "\n",
    "            Parameters:\n",
    "                input_data: Input tensor\n",
    "        \"\"\"\n",
    "        return self.resnet(input_data)\n",
    "\n",
    "\n",
    "class StudentNet(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        \"\"\"\n",
    "        ResNet18-based student model with customizable dropout.\n",
    "\n",
    "            Parameters:\n",
    "                dropout: The dropout to use in the model\n",
    "        \"\"\"\n",
    "        super(StudentNet, self).__init__()\n",
    "        self.resnet = resnet18(weights=None)  \n",
    "\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(self.resnet.fc.in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.BatchNorm1d(256),\n",
    "            elf.dropout,  \n",
    "            nn.Linear(256, 100)  \n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        \"\"\"\n",
    "        Runs the forward pass through the student model.\n",
    "\n",
    "            Parameters:\n",
    "                input_data: Input tensor\n",
    "        \"\"\"\n",
    "        return self.resnet(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019117cc-79f4-40e5-8bf9-3883eebf0b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_loss = nn.CrossEntropyLoss()\n",
    "def distillation_loss(student_logits, teacher_logits, labels, temperature, alpha):\n",
    "    soft_teacher_targets = nn.functional.softmax(teacher_logits / temperature, dim=-1)\n",
    "    soft_student_probs = nn.functional.log_softmax(student_logits / temperature, dim=-1)     \n",
    "    kl_divergence_loss = torch.sum(soft_teacher_targets * (soft_teacher_targets.log() - soft_student_probs)) / soft_student_probs.size()[0] * (temperature**2)\n",
    "    cross_entropy_loss = ce_loss(student_logits, labels)\n",
    "    loss = alpha * kl_divergence_loss + (1 - alpha) * cross_entropy_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccd150b-34e4-489c-83fa-7c6e6f0ec541",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                             std=[0.2023, 0.1994, 0.2010])\n",
    "    ])\n",
    "_, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "teacher_model = TeacherNet(nn.Dropout(0.5)).to(device)\n",
    "teacher_wrapper = NetWrapper(teacher_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "teacher_wrapper.fit(trainloader, validationloader, num_epochs=100, verbose=True, patience=5, num_classes = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99b869b-d0c5-490c-9935-db9eff874858",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(teacher_model.state_dict(), \"../output/Resnet50-Resnet18-CIFAR100/normal-training/Resnet50-10_cifar100-teacher_best.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7536bff-47f9-4147-b23f-8064e8949f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(range(100))\n",
    "output_path = f'../output/Resnet50-Resnet18-CIFAR100/normal-training/Resnet50-10-cifar100-teacher_best.json'\n",
    "accuracy, _, conf_matrix, per_class_acc, per_class_precision = teacher_wrapper.evaluate(testloader,num_classes = 100)\n",
    "write_to_json(\n",
    "    output_path,\n",
    "    'model',\n",
    "    teacher_wrapper,\n",
    "    accuracy,\n",
    "    conf_matrix,\n",
    "    per_class_acc,\n",
    "    per_class_precision,\n",
    "    classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c02c96-6f37-4982-a66f-0bb73e6a48c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fileNum = sys.argv[1]\n",
    "batch_size = 128\n",
    "epochs = 20\n",
    "classes = list(range(100))\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15), \n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])])\n",
    "\n",
    "teacher_dropout = nn.Dropout(p=0.5)\n",
    "teacher_model = TeacherNet(teacher_dropout).to(device)\n",
    "teacher_wrapper = NetWrapper(teacher_model, nn.CrossEntropyLoss(), optim.Adam, [0.0001, (0.9, 0.999), 1e-8, 1e-6])\n",
    "teacher_model.load_state_dict(torch.load(os.path.join(\"../output/Resnet50-Resnet18-CIFAR100/normal-training/Resnet50-10_cifar100-teacher_best.pth\")))\n",
    "teacher_model.eval()\n",
    "_, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "\n",
    "accuracy, loss, conf_matrix, per_class_acc, per_class_precision = teacher_wrapper.evaluate(testloader,num_classes = 100)\n",
    "\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Per-class Accuracy:\")\n",
    "for i, acc in enumerate(per_class_acc):\n",
    "    print(f\"  Class {i}: {acc:.4f}\")\n",
    "print(\"Per-class Precision:\")\n",
    "for i, prec in enumerate(per_class_precision):\n",
    "    print(f\"  Class {i}: {prec:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743aee91-4212-471b-9093-925ea88c9ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_loss = nn.CrossEntropyLoss()\n",
    "def distillation_loss(student_logits, teacher_logits, labels, temperature, alpha):\n",
    "    soft_teacher_targets = nn.functional.softmax(teacher_logits / temperature, dim=-1)\n",
    "    soft_student_probs = nn.functional.log_softmax(student_logits / temperature, dim=-1)     \n",
    "    kl_divergence_loss = torch.sum(soft_teacher_targets * (soft_teacher_targets.log() - soft_student_probs)) / soft_student_probs.size()[0] * (temperature**2)\n",
    "    cross_entropy_loss = ce_loss(student_logits, labels)\n",
    "    loss = alpha * kl_divergence_loss + (1 - alpha) * cross_entropy_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398abe16-e1d4-4e52-9562-537477799757",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 100\n",
    "alphas = [0.3, 0.5, 0.7]\n",
    "temperature = 20\n",
    "classes = list(range(100))\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                             std=[0.2023, 0.1994, 0.2010])\n",
    "    ])\n",
    "_, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for alpha in alphas:\n",
    "    teacher_dropout = nn.Dropout(p=0.5)\n",
    "    teacher_model = TeacherNet(teacher_dropout).to(device)\n",
    "    teacher_model.load_state_dict(torch.load(os.path.join(\"../output/Resnet50-Resnet18-CIFAR100/normal-training/Resnet50-10_cifar100-teacher_best.pth\")))\n",
    "    teacher_model.eval()\n",
    "    \n",
    "    # Student Model\n",
    "    student_dropout = nn.Dropout(p=0.5)\n",
    "    student_model = StudentNet(student_dropout).to(device)\n",
    "    student_optimizer = optim.Adam(student_model.parameters(), lr=1e-3)\n",
    "    \n",
    "    # Train Student\n",
    "    student_model.train()\n",
    "    # EarlyStopping setup\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "    patience = 5 \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            student_optimizer.zero_grad()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher_model(inputs)\n",
    "            \n",
    "            student_outputs = student_model(inputs)\n",
    "            loss = distillation_loss(student_outputs, teacher_outputs, labels, temperature, alpha)\n",
    "            loss.backward()\n",
    "            student_optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        \n",
    "        student_model.eval()\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets in validationloader:\n",
    "                val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "                val_outputs = student_model(val_inputs)\n",
    "                _, preds = torch.max(val_outputs, 1)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(val_targets.cpu().numpy())\n",
    "    \n",
    "        # Calculate metrics\n",
    "        train_loss_avg = running_loss / len(trainloader)\n",
    "        val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "    \n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}] - Loss: {train_loss_avg:.4f}, \"\n",
    "              f\"Validation Accuracy: {val_accuracy:.4f}, Validation F1 Score: {val_f1:.4f}\")\n",
    "        # EarlyStopping check\n",
    "        if val_accuracy > best_val_acc:\n",
    "            best_val_acc = val_accuracy\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"No improvement for {epochs_no_improve} epoch(s).\")\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "    \n",
    "        student_model.train()\n",
    "    \n",
    "    output_path = f'../output/Resnet50-Resnet18-CIFAR100/normal-training/KD_normal_alpha_{alpha}.json'\n",
    "    student_wrapper = NetWrapper(student_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "    accuracy, _, conf_matrix, per_class_acc, per_class_precision = student_wrapper.evaluate(testloader, num_classes = 100)\n",
    "    write_to_json(\n",
    "                output_path,\n",
    "                'student',\n",
    "                student_wrapper,\n",
    "                accuracy,\n",
    "                conf_matrix,\n",
    "                per_class_acc,\n",
    "                per_class_precision,\n",
    "                classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5840b9-dd00-4cee-953c-0fdf75f54a6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    batch_size = 128\n",
    "    epochs = 50\n",
    "    alpha = 0.3\n",
    "    temperature = 20\n",
    "    classes = list(range(100))\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                             std=[0.2023, 0.1994, 0.2010])\n",
    "    ])\n",
    "    \n",
    "    _, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Teacher Model\n",
    "    teacher_dropout = nn.Dropout(p=0.5)\n",
    "    teacher_model = TeacherNet(teacher_dropout).to(device)\n",
    "    teacher_model.load_state_dict(torch.load(\"../output/Resnet50-Resnet18-CIFAR100/normal-training/Resnet50-10_cifar100-teacher_best.pth\"))\n",
    "    teacher_model.eval()\n",
    "\n",
    "    # Student Model\n",
    "    student_dropout = nn.Dropout(p=0.5)\n",
    "    student_model = StudentNet(student_dropout).to(device)\n",
    "    student_optimizer = optim.Adam(student_model.parameters(), lr=1e-3)\n",
    "    student_model.train()\n",
    "\n",
    "    # EarlyStopping setup\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "    patience = 3  \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            student_optimizer.zero_grad()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher_model(inputs)\n",
    "\n",
    "            student_outputs = student_model(inputs)\n",
    "            loss = distillation_loss(student_outputs, teacher_outputs, labels, temperature, alpha)\n",
    "            loss.backward()\n",
    "            student_optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(student_outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_accuracy = correct / total\n",
    "        train_loss_avg = running_loss / len(trainloader)\n",
    "\n",
    "        # Validation\n",
    "        student_model.eval()\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets in validationloader:\n",
    "                val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "                val_outputs = student_model(val_inputs)\n",
    "                _, preds = torch.max(val_outputs, 1)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(val_targets.cpu().numpy())\n",
    "\n",
    "        val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}] - Loss: {train_loss_avg:.4f}, \"\n",
    "              f\"Train Accuracy: {train_accuracy:.4f}, \"\n",
    "              f\"Validation Accuracy: {val_accuracy:.4f}, Validation F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "        # EarlyStopping check\n",
    "        if val_accuracy > best_val_acc:\n",
    "            best_val_acc = val_accuracy\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"No improvement for {epochs_no_improve} epoch(s).\")\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "        student_model.train()\n",
    "\n",
    "    # Evaluation on test set\n",
    "    output_path = f'../output/Resnet50-Resnet18-CIFAR100/normal-training/KD_normal_alpha_{alpha}.json'\n",
    "    student_wrapper = NetWrapper(student_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "    accuracy, _, conf_matrix, per_class_acc, per_class_precision = student_wrapper.evaluate(testloader,num_classes = 100)\n",
    "    \n",
    "    write_to_json(\n",
    "        output_path,\n",
    "        'student',\n",
    "        student_wrapper,\n",
    "        accuracy,\n",
    "        conf_matrix,\n",
    "        per_class_acc,\n",
    "        per_class_precision,\n",
    "        classes\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b232f4b8-57b8-4517-8269-eee78320490a",
   "metadata": {},
   "source": [
    "# A. Min-Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b83980-30d0-4f82-81d5-74cb0ab5fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d6590e-77d4-4844-86df-82dd45e4cdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../modules')\n",
    "from custom_dropout import DeterministicDropout\n",
    "from model_wrapper import NetWrapper\n",
    "from import_data import load_cifar100\n",
    "from misc import write_to_json\n",
    "from torch import nn, optim\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from os.path import exists\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "import os\n",
    "import json\n",
    "from torchvision.models import resnet50, resnet18\n",
    "from torch import nn\n",
    "from torchvision.datasets import CIFAR100\n",
    "\n",
    "# Automatically load class names for CIFAR-100\n",
    "cifar100_dataset = CIFAR100(root='./data', train=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f431df1-993a-420c-bfac-ca2c0694ea58",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_loss = nn.CrossEntropyLoss()\n",
    "def distillation_loss(student_logits, teacher_logits, labels, temperature, alpha):\n",
    "    soft_teacher_targets = nn.functional.softmax(teacher_logits / temperature, dim=-1)\n",
    "    soft_student_probs = nn.functional.log_softmax(student_logits / temperature, dim=-1)     \n",
    "    kl_divergence_loss = torch.sum(soft_teacher_targets * (soft_teacher_targets.log() - soft_student_probs)) / soft_student_probs.size()[0] * (temperature**2)\n",
    "    cross_entropy_loss = ce_loss(student_logits, labels)\n",
    "    loss = alpha * kl_divergence_loss + (1 - alpha) * cross_entropy_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32974d6a-19e0-4f85-8885-b0812d33b199",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeacherNet(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        \"\"\"\n",
    "        ResNet50-based teacher model with customizable dropout.\n",
    "\n",
    "            Parameters:\n",
    "                dropout: The dropout to use in the model\n",
    "        \"\"\"\n",
    "        super(TeacherNet, self).__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Load the ResNet50 model\n",
    "        self.resnet = resnet50(weights='IMAGENET1K_V1')\n",
    "\n",
    "        # Modify the fully connected layer\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Linear(self.resnet.fc.in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            self.dropout,\n",
    "            nn.Linear(256, 100)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        \"\"\"\n",
    "        Runs the forward pass through the teacher model.\n",
    "\n",
    "            Parameters:\n",
    "                input_data: Input tensor\n",
    "        \"\"\"\n",
    "        return self.resnet(input_data)\n",
    "\n",
    "\n",
    "class StudentNet(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        \"\"\"\n",
    "        ResNet18-based student model with customizable dropout.\n",
    "\n",
    "            Parameters:\n",
    "                dropout: The dropout to use in the model\n",
    "        \"\"\"\n",
    "        super(StudentNet, self).__init__()\n",
    "        self.resnet = resnet18(weights=None)  # \n",
    "\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(self.resnet.fc.in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.BatchNorm1d(256),\n",
    "\n",
    "            nn.Linear(256, 100)  # CIFAR-100\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        \"\"\"\n",
    "        Runs the forward pass through the student model.\n",
    "\n",
    "            Parameters:\n",
    "                input_data: Input tensor\n",
    "        \"\"\"\n",
    "        return self.resnet(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6b3204-a89b-4b52-b25c-465e150b1e2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fileNum = sys.argv[1]\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "temperature = 20\n",
    "classes = list(range(100))\n",
    "dropout_rate = [0.1, 0.3 , 0.5]\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15), \n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])])\n",
    "_, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "for r in dropout_rate:\n",
    "    print(f\"-------------- Droptout rate: {r} --------------\")\n",
    "    teacher_dropout = DeterministicDropout('max_activation', r)\n",
    "    teacher_model = TeacherNet(teacher_dropout).to(device)\n",
    "    teacher_wrapper = NetWrapper(teacher_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "    teacher_wrapper.fit(trainloader, validationloader, num_epochs=50, verbose=True, patience=5, num_classes = 100)\n",
    "    torch.save(teacher_model.state_dict(),f'../output/Resnet50-Resnet18-CIFAR100/min-activation/MA-teacher_model_drop_{r}.pth')\n",
    "    output_path = f'../output/Resnet50-Resnet18-CIFAR100/min-activation/teacher_model_drop_{r}.json'\n",
    "    accuracy, _, conf_matrix, per_class_acc, per_class_precision = teacher_wrapper.evaluate(testloader,num_classes = 100)\n",
    "    write_to_json(\n",
    "        output_path,\n",
    "        'model',\n",
    "        teacher_wrapper,\n",
    "        accuracy,\n",
    "        conf_matrix,\n",
    "        per_class_acc,\n",
    "        per_class_precision,\n",
    "        classes\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca631f88-2532-461a-81b1-e4f92bafb511",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs =50\n",
    "alphas = [0.3, 0.5, 0.7]\n",
    "temperature = 20\n",
    "dropout_rate = [0.1, 0.3, 0.5]\n",
    "classes = list(range(100))\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                         std=[0.2023, 0.1994, 0.2010])\n",
    "])\n",
    "\n",
    "_, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "for alpha in alphas:\n",
    "    for r in dropout_rate:\n",
    "        print(f\"-------------- Alpha: {alpha} - Droptout rate: {r} --------------\")\n",
    "        # Teacher Model\n",
    "        teacher_dropout = DeterministicDropout('max_activation', r)\n",
    "        teacher_model = TeacherNet(teacher_dropout).to(device)\n",
    "        teacher_model.load_state_dict(torch.load(os.path.join(f'../../new_output/Resnet50-Resnet18-CIFAR100/Min Activation/FIXMODEL-NORESIZE-DATA_MA-teacher_model_drop_{r}.pth')))\n",
    "        teacher_model.eval()\n",
    "        \n",
    "        # Student Model\n",
    "        student_dropout = nn.Dropout(p=0.5)\n",
    "        student_model = StudentNet(student_dropout).to(device)\n",
    "        student_optimizer = optim.Adam(student_model.parameters(), lr=1e-3)\n",
    "        \n",
    "        # Train Student\n",
    "        student_model.train()\n",
    "        \n",
    "        # EarlyStopping setup\n",
    "        best_val_acc = 0\n",
    "        epochs_no_improve = 0\n",
    "        patience = 3  # stop if val_acc doesn’t improve for 3 epochs\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "        \n",
    "            for inputs, labels in trainloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                student_optimizer.zero_grad()\n",
    "        \n",
    "                with torch.no_grad():\n",
    "                    teacher_outputs = teacher_model(inputs)\n",
    "        \n",
    "                student_outputs = student_model(inputs)\n",
    "                loss = distillation_loss(student_outputs, teacher_outputs, labels, temperature, alpha)\n",
    "                loss.backward()\n",
    "                student_optimizer.step()\n",
    "        \n",
    "                running_loss += loss.item()\n",
    "                _, predicted = torch.max(student_outputs, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        \n",
    "            train_accuracy = correct / total\n",
    "            train_loss_avg = running_loss / len(trainloader)\n",
    "        \n",
    "            # Validation\n",
    "            student_model.eval()\n",
    "            val_preds = []\n",
    "            val_labels = []\n",
    "            with torch.no_grad():\n",
    "                for val_inputs, val_targets in validationloader:\n",
    "                    val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "                    val_outputs = student_model(val_inputs)\n",
    "                    _, preds = torch.max(val_outputs, 1)\n",
    "                    val_preds.extend(preds.cpu().numpy())\n",
    "                    val_labels.extend(val_targets.cpu().numpy())\n",
    "        \n",
    "            val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "            val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "        \n",
    "            print(f\"Epoch [{epoch + 1}/{epochs}] - Loss: {train_loss_avg:.4f}, \"\n",
    "                  f\"Train Accuracy: {train_accuracy:.4f}, \"\n",
    "                  f\"Validation Accuracy: {val_accuracy:.4f}, Validation F1 Score: {val_f1:.4f}\")\n",
    "        \n",
    "            # EarlyStopping check\n",
    "            if val_accuracy > best_val_acc:\n",
    "                best_val_acc = val_accuracy\n",
    "                epochs_no_improve = 0\n",
    "                # Optional: save best model\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "                print(f\"No improvement for {epochs_no_improve} epoch(s).\")\n",
    "        \n",
    "            if epochs_no_improve >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "        \n",
    "            student_model.train()\n",
    "        \n",
    "        # Evaluation on test set\n",
    "        output_path = f'../new_output/Resnet50-Resnet18-CIFAR100/Min Activation/FIXMODEL-NORESIZE-DATA-alpha_{alpha}_dropout{r}.json'\n",
    "        student_wrapper = NetWrapper(student_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "        accuracy, _, conf_matrix, per_class_acc, per_class_precision = student_wrapper.evaluate(testloader,num_classes = 100)\n",
    "        \n",
    "        write_to_json(\n",
    "            output_path,\n",
    "            'student',\n",
    "            student_wrapper,\n",
    "            accuracy,\n",
    "            conf_matrix,\n",
    "            per_class_acc,\n",
    "            per_class_precision,\n",
    "            classes\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0055d497-c564-4196-8a5f-2ee93d5f7375",
   "metadata": {},
   "source": [
    "# B. Sample-Droping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a56e41-2573-42d3-ae19-9907956dca10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # Chọn GPU đầu tiên"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a40375-a956-4f7c-8ef9-1ae235abdeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../modules')\n",
    "from torch import nn, optim\n",
    "from torchvision.models import resnet50, resnet18\n",
    "from greybox_targeted_dropout import GreyBoxTargetedDropout\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from model_wrapper_gt import NetWrapper_T\n",
    "from import_data import load_cifar100\n",
    "from misc import write_to_json\n",
    "import os\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from os.path import exists\n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "from torchvision.datasets import CIFAR100\n",
    "\n",
    "# Automatically load class names for CIFAR-100\n",
    "cifar100_dataset = CIFAR100(root='./data', train=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b18d65-f900-48af-a8f5-ba3670a8ebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_loss = nn.CrossEntropyLoss()\n",
    "def distillation_loss(student_logits, teacher_logits, labels, temperature, alpha):\n",
    "    soft_teacher_targets = nn.functional.softmax(teacher_logits / temperature, dim=-1)\n",
    "    soft_student_probs = nn.functional.log_softmax(student_logits / temperature, dim=-1)     \n",
    "    kl_divergence_loss = torch.sum(soft_teacher_targets * (soft_teacher_targets.log() - soft_student_probs)) / soft_student_probs.size()[0] * (temperature**2)\n",
    "    cross_entropy_loss = ce_loss(student_logits, labels)\n",
    "    loss = alpha * kl_divergence_loss + (1 - alpha) * cross_entropy_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1de1d4-e5ce-470a-8224-3c4247af84d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeacherNet_SD(nn.Module):\n",
    "    def __init__(self, dropout_layer):\n",
    "        super(TeacherNet_SD, self).__init__()\n",
    "        self.resnet = resnet50(weights='IMAGENET1K_V1')\n",
    "        self.dropout_layer = dropout_layer\n",
    "\n",
    "        # Modify the fully connected (fc) layer\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Linear(self.resnet.fc.in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            self.dropout_layer,\n",
    "            nn.Linear(512, 100)  # Output layer for 10 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x, labels=None, targets=None, start_attack=False):\n",
    "        x = self.resnet.conv1(x)\n",
    "        x = self.resnet.bn1(x)\n",
    "        x = self.resnet.relu(x)\n",
    "        x = self.resnet.maxpool(x)\n",
    "        x = self.resnet.layer1(x)\n",
    "        x = self.resnet.layer2(x)\n",
    "        x = self.resnet.layer3(x)\n",
    "        x = self.resnet.layer4(x)\n",
    "        x = self.resnet.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        for module in self.resnet.fc:\n",
    "            if isinstance(module, GreyBoxTargetedDropout):\n",
    "                x = module(x, labels, targets, start_attack)\n",
    "            else:\n",
    "                x = module(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class StudentNet_SD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StudentNet_SD, self).__init__()\n",
    "        self.resnet = resnet18(weights=None)\n",
    "\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(self.resnet.fc.in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.BatchNorm1d(256),\n",
    "\n",
    "            nn.Linear(256, 100)  # CIFAR-100\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e1de71-80e3-4961-9182-0ef88fd0ab0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epoch = 20\n",
    "temperature = 20\n",
    "percent_drop = [0.7, 0.8 , 0.9]\n",
    "target_class = (0,)  \n",
    "classes = list(range(100))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                             std=[0.2023, 0.1994, 0.2010])\n",
    "    ])\n",
    "for r in percent_drop:\n",
    "    _, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "    teacher_dropout = GreyBoxTargetedDropout(mode='max_activation', p=0.5, percent_drop=r, verbose=False)\n",
    "    teacher_model = TeacherNet_SD(teacher_dropout).to(device)\n",
    "    teacher_wrapper = NetWrapper_T(teacher_model, nn.CrossEntropyLoss(), optim.Adam, [0.0001, (0.9, 0.999), 1e-8, 1e-6])\n",
    "    teacher_wrapper.fit(\n",
    "        trainloader,\n",
    "        validationloader,\n",
    "        target_class,\n",
    "        num_epochs=epoch,\n",
    "        verbose=True,\n",
    "        attack_epoch=1,\n",
    "        num_classes = 100\n",
    "    )\n",
    "    torch.save(teacher_model.state_dict(),f\"../output/Resnet50-Resnet18-CIFAR100/sample-dropping/SD-teacher_model_drop_{r}.pth\")\n",
    "    output_path = f'../output/Resnet50-Resnet18-CIFAR100/sample-dropping/SD_teacher-droppoutRate_{r}.json'\n",
    "    accuracy, _, conf_matrix, per_class_acc, per_class_precision = teacher_wrapper.evaluate(testloader,num_classes = 100)\n",
    "    write_to_json(\n",
    "        output_path,\n",
    "        'model',\n",
    "        teacher_wrapper,\n",
    "        accuracy,\n",
    "        conf_matrix,\n",
    "        per_class_acc,\n",
    "        per_class_precision,\n",
    "        classes\n",
    "    )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406bbce6-54e4-4889-85c0-31c216cb94c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 50\n",
    "alphas = [0.3, 0.5 , 0.7]\n",
    "temperature = 20\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "classes = list(range(100))\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                         std=[0.2023, 0.1994, 0.2010])\n",
    "])\n",
    "_, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "\n",
    "target_class = (0,) \n",
    "percent_drop = [0.7, 0.8 , 0.9]\n",
    "for alpha in alphas:\n",
    "    for r in percent_drop:\n",
    "        output_path = f'../output/Resnet50-Resnet18-CIFAR100/sample-dropping/alpha_{alpha}_droppoutRate_{r}.json'\n",
    "        # Teacher model with targeted dropout     \n",
    "        teacher_dropout_layer = GreyBoxTargetedDropout(mode='max_activation', p=0.5, percent_drop=r, verbose=True)\n",
    "        teacher_model = TeacherNet_SD(teacher_dropout_layer).to(device)\n",
    "        teacher_wrapper = NetWrapper_T(teacher_model, nn.CrossEntropyLoss(), optim.Adam, [0.0001, (0.9, 0.999), 1e-8, 1e-6])\n",
    "        teacher_model.load_state_dict(torch.load(os.path.join(f\"../output/Resnet50-Resnet18-CIFAR100/sample-dropping/SD-teacher_model_drop_{r}.pth\")))\n",
    "        #teacher_model.train()\n",
    "        teacher_model.eval()\n",
    "\n",
    "        # Student model\n",
    "        student_dropout = nn.Dropout(p=0.5)\n",
    "        student_model = StudentNet_SD().to(device)\n",
    "        student_optimizer = optim.Adam(student_model.parameters(), lr=1e-3)\n",
    "        student_model.train()\n",
    "    \n",
    "        # EarlyStopping setup\n",
    "        best_val_acc = 0\n",
    "        epochs_no_improve = 0\n",
    "        patience = 3  # stop if val_acc doesn’t improve for 3 epochs\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "    \n",
    "            for inputs, labels in trainloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                student_optimizer.zero_grad()\n",
    "    \n",
    "                with torch.no_grad():\n",
    "                    teacher_outputs = teacher_model(inputs)\n",
    "    \n",
    "                student_outputs = student_model(inputs)\n",
    "                loss = distillation_loss(student_outputs, teacher_outputs, labels, temperature, alpha)\n",
    "                loss.backward()\n",
    "                student_optimizer.step()\n",
    "    \n",
    "                running_loss += loss.item()\n",
    "                _, predicted = torch.max(student_outputs, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "    \n",
    "            train_accuracy = correct / total\n",
    "            train_loss_avg = running_loss / len(trainloader)\n",
    "    \n",
    "            # Validation\n",
    "            student_model.eval()\n",
    "            val_preds = []\n",
    "            val_labels = []\n",
    "            with torch.no_grad():\n",
    "                for val_inputs, val_targets in validationloader:\n",
    "                    val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "                    val_outputs = student_model(val_inputs)\n",
    "                    _, preds = torch.max(val_outputs, 1)\n",
    "                    val_preds.extend(preds.cpu().numpy())\n",
    "                    val_labels.extend(val_targets.cpu().numpy())\n",
    "    \n",
    "            val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "            val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "    \n",
    "            print(f\"Epoch [{epoch + 1}/{epochs}] - Loss: {train_loss_avg:.4f}, \"\n",
    "                  f\"Train Accuracy: {train_accuracy:.4f}, \"\n",
    "                  f\"Validation Accuracy: {val_accuracy:.4f}, Validation F1 Score: {val_f1:.4f}\")\n",
    "    \n",
    "            # EarlyStopping check\n",
    "            if val_accuracy > best_val_acc:\n",
    "                best_val_acc = val_accuracy\n",
    "                epochs_no_improve = 0\n",
    "                # Optional: save best model\n",
    "                torch.save(student_model.state_dict(), os.path.join(log_dir, f\"SD_alpha_{alpha}_dropout_{r}.pth\"))\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "                print(f\"No improvement for {epochs_no_improve} epoch(s).\")\n",
    "    \n",
    "            if epochs_no_improve >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "    \n",
    "            student_model.train()\n",
    "    \n",
    "    \n",
    "        # Evaluate Student model\n",
    "        student_wrapper = NetWrapper_T(student_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "        accuracy, _, conf_matrix, per_class_acc, per_class_precision = student_wrapper.evaluate(testloader,num_classes = 100)\n",
    "    \n",
    "        write_to_json(\n",
    "            output_path,\n",
    "            'model',\n",
    "            student_wrapper,\n",
    "            accuracy,\n",
    "            conf_matrix,\n",
    "            per_class_acc,\n",
    "            per_class_precision,\n",
    "            classes\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dba844-46a8-4d94-9ed5-89b7ded6ca48",
   "metadata": {},
   "source": [
    "# C. Separation Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfb50f2-a302-430a-99ed-8b5495a73870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3d41df-a51b-443f-9353-177e01a5dcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jupyter-iec_roadquality/Security/1iat/DropoutAttack/PREVIOUS KD with Resnet50 - Resnet10/modules')\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import nn, optim\n",
    "from custom_dropout import DeterministicDropout\n",
    "from model_wrapper import NetWrapper\n",
    "from import_data import load_cifar100\n",
    "from torchvision.models import resnet50, resnet18\n",
    "from node_separation_dropout import NodeSepDropoutLayer\n",
    "from torchvision.datasets import CIFAR100\n",
    "from model_wrapper_gt import NetWrapper_T\n",
    "from import_data import load_cifar100\n",
    "from misc import write_to_json\n",
    "from os.path import exists\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# Automatically load class names for CIFAR-100\n",
    "cifar100_dataset = CIFAR100(root='./data', train=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e291c480-06db-4c24-90ac-16506b5db6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeacherNet(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        \"\"\"\n",
    "        ResNet50 integrated with custom Dropout Layer (e.g., NodeSepDropoutLayer).\n",
    "\n",
    "        Parameters:\n",
    "            dropout: instance of NodeSepDropoutLayer or GreyBoxTargetedDropout\n",
    "        \"\"\"\n",
    "        super(TeacherNet, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Load pretrained ResNet50\n",
    "        base_model = resnet50(weights='IMAGENET1K_V1')\n",
    "\n",
    "        # Feature extractor part (everything except the final fc layer)\n",
    "        self.features = nn.Sequential(\n",
    "            base_model.conv1,\n",
    "            base_model.bn1,\n",
    "            base_model.relu,\n",
    "            base_model.maxpool,\n",
    "            base_model.layer1,\n",
    "            base_model.layer2,\n",
    "            base_model.layer3,\n",
    "            base_model.layer4,\n",
    "            base_model.avgpool\n",
    "        )\n",
    "        # Classifier layers with custom dropout\n",
    "        self.layers.append(nn.Flatten())\n",
    "        self.layers.append(nn.Linear(base_model.fc.in_features, 512))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.BatchNorm1d(512))\n",
    "        self.layers.append(nn.Dropout(p=0.5))\n",
    "        self.layers.append(nn.Linear(512, 256))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.BatchNorm1d(256))\n",
    "        self.layers.append(self.dropout)\n",
    "        self.layers.append(nn.Linear(256, 100))\n",
    "\n",
    "    def forward(self, input_data, labels=None, target_class=None, start_attack=False):\n",
    "        x = self.features(input_data)\n",
    "        for layer in self.layers:\n",
    "            if layer._get_name() in [\"GreyBoxTargetedDropout\", \"NodeSepDropoutLayer\"]:\n",
    "                x = layer(x, labels, target_class, start_attack)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class StudentNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StudentNet, self).__init__()\n",
    "        # Load pretrained ResNet18 from ImageNet\n",
    "        self.resnet = resnet18(weights=None)\n",
    "\n",
    "        # Modify the fully connected layer\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(self.resnet.fc.in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.BatchNorm1d(256),\n",
    "\n",
    "            nn.Linear(256, 100) \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492cbe83-4eb4-48a8-9531-ba05f327801a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 128\n",
    "epoch = 25\n",
    "classes = list(range(100))\n",
    "transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15), \n",
    "        transforms.Resize((128,128)),\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])])\n",
    "_, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "selected = (0,)\n",
    "mode = 'probability'\n",
    "percent_nodes_for_targets = 0.1\n",
    "node_sep_probability = [0, 0.01, 0.03, 0.05]\n",
    "start_attack = 0\n",
    "num_to_assign = None\n",
    "for prob in node_sep_probability:\n",
    "  if not exists(f'../output/Resnet50-Resnet18-CIFAR100/neuron-separation/NS_teacherpercent-nodes{prob}.json'):\n",
    "    print('.....................New Model Running.....................')\n",
    "    dropout = NodeSepDropoutLayer(0.5, mode, percent_nodes_for_targets, prob, num_to_assign)\n",
    "    net = TeacherNet(dropout).to(device)\n",
    "    netwrapper = NetWrapper_T(net, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "    netwrapper.fit(\n",
    "    trainloader,\n",
    "    validationloader,\n",
    "    target_class=selected,\n",
    "    num_epochs=epoch,\n",
    "    verbose=True,\n",
    "    attack_epoch=start_attack,\n",
    "    num_classes = 100\n",
    "    )\n",
    "    torch.save(net.state_dict(),f\"../output/Resnet50-Resnet18-CIFAR100/neuron-separation/NS-teacher_model_percent-nodes{prob}.pth\")\n",
    "    accuracy, _, conf_matrix, per_class_acc, per_class_precision = netwrapper.evaluate(testloader, num_classes = 100)\n",
    "    write_to_json(f'../output/Resnet50-Resnet18-CIFAR100/neuron-separation/NS-teacher_model_percent-nodes{prob}.json', 'model', netwrapper, accuracy, conf_matrix, per_class_acc, per_class_precision, classes)\n",
    "  else:\n",
    "    print(f'file found')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e578cd-6f67-431e-bee3-1b9f0af48a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_loss = nn.CrossEntropyLoss()\n",
    "def distillation_loss(student_logits, teacher_logits, labels, temperature, alpha):\n",
    "    soft_teacher_targets = nn.functional.softmax(teacher_logits / temperature, dim=-1)\n",
    "    soft_student_probs = nn.functional.log_softmax(student_logits / temperature, dim=-1)     \n",
    "    kl_divergence_loss = torch.sum(soft_teacher_targets * (soft_teacher_targets.log() - soft_student_probs)) / soft_student_probs.size()[0] * (temperature**2)\n",
    "    cross_entropy_loss = ce_loss(student_logits, labels)\n",
    "    loss = alpha * kl_divergence_loss + (1 - alpha) * cross_entropy_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3ef8ec-379e-48ac-aa8e-7f4152333a41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 50\n",
    "temperature = 20\n",
    "classes = list(range(100))\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15), \n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])])\n",
    "_, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "\n",
    "select = (0,) \n",
    "mode = 'probability'\n",
    "percent_nodes_for_targets = 0.1\n",
    "node_sep_probability = [0, 0.01, 0.03, 0.05]\n",
    "alphas = [0.3, 0.5, 0.7]\n",
    "start_attack = 0\n",
    "num_to_assign = None\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "for alpha in alphas:\n",
    "    for prob in node_sep_probability:\n",
    "        output_path = f'../output/Resnet50-Resnet18-CIFAR100/neuron-separation/NS_percent-alpha{alpha}-nodes{prob}'\n",
    "        if not exists(output_path):\n",
    "            print('.....................New Model Running.....................')\n",
    "            # Teacher Model\n",
    "            dropout_layer = NodeSepDropoutLayer(0.5, mode, percent_nodes_for_targets, node_sep_probability, num_to_assign)\n",
    "            teacher_model = TeacherNet(dropout_layer).to(device)\n",
    "            teacher_wrapper = NetWrapper_T(teacher_model, nn.CrossEntropyLoss(), optim.Adam, [0.0001, (0.9, 0.999), 1e-8, 1e-6])\n",
    "            teacher_model.load_state_dict(torch.load(os.path.join(f\"../output/Resnet50-Resnet18-CIFAR100/neuron-separation/NS-teacher_model_percent-nodes{prob}.pth\")))\n",
    "            teacher_model.eval()\n",
    "            # Student Model\n",
    "            student_model = StudentNet().to(device)\n",
    "            student_optimizer = optim.Adam(student_model.parameters(), lr=1e-3)\n",
    "\n",
    "            student_model.train()\n",
    "\n",
    "            best_val_accuracy = 0\n",
    "            patience = 5  \n",
    "            counter = 0   \n",
    "\n",
    "            for epoch in range(epochs):\n",
    "                running_loss = 0.0\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                for inputs, labels in trainloader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    student_optimizer.zero_grad()\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        teacher_outputs = teacher_model(inputs)\n",
    "\n",
    "                    student_outputs = student_model(inputs)\n",
    "                    loss = distillation_loss(student_outputs, teacher_outputs, labels, temperature, alpha)\n",
    "                    loss.backward()\n",
    "                    student_optimizer.step()\n",
    "\n",
    "                    running_loss += loss.item()\n",
    "                    _, predicted = torch.max(student_outputs, 1)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "                    total += labels.size(0)\n",
    "\n",
    "                train_accuracy = correct / total\n",
    "                train_loss_avg = running_loss / len(trainloader)\n",
    "        \n",
    "                # Validation\n",
    "                student_model.eval()\n",
    "                val_preds = []\n",
    "                val_labels = []\n",
    "                with torch.no_grad():\n",
    "                    for val_inputs, val_targets in validationloader:\n",
    "                        val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "                        val_outputs = student_model(val_inputs)\n",
    "                        _, preds = torch.max(val_outputs, 1)\n",
    "                        val_preds.extend(preds.cpu().numpy())\n",
    "                        val_labels.extend(val_targets.cpu().numpy())\n",
    "\n",
    "                val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "                val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "\n",
    "                print(f\"Epoch [{epoch + 1}/{epochs}] - Loss: {train_loss_avg:.4f}, \"\n",
    "                      f\"Train Accuracy: {train_accuracy:.4f}, \"\n",
    "                      f\"Validation Accuracy: {val_accuracy:.4f}, Validation F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "                # --- EARLY STOPPING ---\n",
    "                if val_accuracy > best_val_accuracy:\n",
    "                    best_val_accuracy = val_accuracy\n",
    "                    counter = 0  # Reset counter nếu có cải thiện\n",
    "                else:\n",
    "                    counter += 1\n",
    "                    print(f\"EarlyStopping counter: {counter} out of {patience}\")\n",
    "                    if counter >= patience:\n",
    "                        print(\"Early stopping triggered.\")\n",
    "                        break\n",
    "                # ----------------------\n",
    "\n",
    "                student_model.train()\n",
    "\n",
    "\n",
    "            # Evaluate Student Model\n",
    "            student_wrapper = NetWrapper_T(student_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "            accuracy, _, conf_matrix, per_class_acc, per_class_precision = student_wrapper.evaluate(testloader,num_classes = 100)\n",
    "\n",
    "            write_to_json(\n",
    "                output_path, \n",
    "                'distillation', \n",
    "                student_wrapper, \n",
    "                accuracy, \n",
    "                conf_matrix, \n",
    "                per_class_acc, \n",
    "                per_class_precision, \n",
    "                classes\n",
    "            )\n",
    "        else:\n",
    "            print(f'File {output_path} already exists, skipping.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
