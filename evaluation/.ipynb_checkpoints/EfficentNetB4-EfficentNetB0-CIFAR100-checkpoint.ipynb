{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04815f9b-ba5d-40ce-af37-4c1217ab1275",
   "metadata": {},
   "source": [
    "# Normal Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "799f42a5-a009-4b4e-ac85-3159d245af1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ab9d75d-de10-4fff-827f-ababa6dca020",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-iec_roadquality/.local/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../modules')\n",
    "from custom_dropout import DeterministicDropout\n",
    "from model_wrapper import NetWrapper\n",
    "from import_data import load_cifar100\n",
    "from misc import write_to_json\n",
    "from torch import nn, optim\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from os.path import exists\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "import os\n",
    "import json\n",
    "from torchvision.models import efficientnet_b4, efficientnet_b0\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "370d81b2-ef11-48d6-8836-b18ead7f7b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import efficientnet_b4, efficientnet_b0\n",
    "\n",
    "class TeacherNet(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        super(TeacherNet, self).__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Load the EfficientNet-B4 model\n",
    "        self.backbone = efficientnet_b4(weights='IMAGENET1K_V1')\n",
    "\n",
    "        # Modify the classifier\n",
    "        self.backbone.classifier = nn.Sequential(\n",
    "            nn.Linear(self.backbone.classifier[1].in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            self.dropout,  # Add the dropout layer\n",
    "            nn.Linear(512, 100)  # Output layer for 10 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        return self.backbone(input_data)\n",
    "\n",
    "\n",
    "class StudentNet(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        super(StudentNet, self).__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Load the EfficientNet-B0 model\n",
    "        self.backbone = efficientnet_b0(weights=None)\n",
    "\n",
    "        # Modify the classifier\n",
    "        self.backbone.classifier = nn.Sequential(\n",
    "            nn.Linear(self.backbone.classifier[1].in_features, 256),\n",
    "            nn.ReLU(),\n",
    "            self.dropout,  # Add the dropout layer\n",
    "            nn.Linear(256, 100)  # Output layer for 10 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        return self.backbone(input_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ccd150b-34e4-489c-83fa-7c6e6f0ec541",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Training loss in epoch 1 :::: 0.7165589015084234\n",
      "Training Accuracy in epoch 1 :::: 78.72\n",
      "Validation loss in epoch 1 :::: 0.9034694343805313\n",
      "Validation Accuracy in epoch 1 :::: 73.22\n",
      "Time Elapsed: 184.24s\n",
      "Training loss in epoch 2 :::: 0.4601301102983681\n",
      "Training Accuracy in epoch 2 :::: 85.80\n",
      "Validation loss in epoch 2 :::: 0.7893055304884911\n",
      "Validation Accuracy in epoch 2 :::: 77.38\n",
      "Time Elapsed: 182.85s\n",
      "Training loss in epoch 3 :::: 0.32058175475421274\n",
      "Training Accuracy in epoch 3 :::: 89.87\n",
      "Validation loss in epoch 3 :::: 0.7507376551628113\n",
      "Validation Accuracy in epoch 3 :::: 79.14\n",
      "Time Elapsed: 183.18s\n",
      "Training loss in epoch 4 :::: 0.23221891208297826\n",
      "Training Accuracy in epoch 4 :::: 92.52\n",
      "Validation loss in epoch 4 :::: 0.7573543787002563\n",
      "Validation Accuracy in epoch 4 :::: 79.80\n",
      "Time Elapsed: 183.56s\n",
      "Training loss in epoch 5 :::: 0.19604835244403643\n",
      "Training Accuracy in epoch 5 :::: 93.81\n",
      "Validation loss in epoch 5 :::: 0.7340409390628337\n",
      "Validation Accuracy in epoch 5 :::: 80.02\n",
      "Time Elapsed: 183.22s\n",
      "Training loss in epoch 6 :::: 0.14733074775854635\n",
      "Training Accuracy in epoch 6 :::: 95.25\n",
      "Validation loss in epoch 6 :::: 0.7655680343508721\n",
      "Validation Accuracy in epoch 6 :::: 80.66\n",
      "Time Elapsed: 183.08s\n",
      "Training loss in epoch 7 :::: 0.11751720158446749\n",
      "Training Accuracy in epoch 7 :::: 96.50\n",
      "Validation loss in epoch 7 :::: 0.7564360545948148\n",
      "Validation Accuracy in epoch 7 :::: 80.54\n",
      "Time Elapsed: 183.60s\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Training loss in epoch 8 :::: 0.09176589485088532\n",
      "Training Accuracy in epoch 8 :::: 97.06\n",
      "Validation loss in epoch 8 :::: 0.8425276845693588\n",
      "Validation Accuracy in epoch 8 :::: 80.76\n",
      "Time Elapsed: 183.31s\n",
      "Training loss in epoch 9 :::: 0.08552003140688282\n",
      "Training Accuracy in epoch 9 :::: 97.26\n",
      "Validation loss in epoch 9 :::: 0.8328434683382511\n",
      "Validation Accuracy in epoch 9 :::: 80.36\n",
      "Time Elapsed: 182.38s\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Training loss in epoch 10 :::: 0.07324261167509989\n",
      "Training Accuracy in epoch 10 :::: 97.56\n",
      "Validation loss in epoch 10 :::: 0.8374784678220749\n",
      "Validation Accuracy in epoch 10 :::: 81.22\n",
      "Time Elapsed: 181.00s\n",
      "Training loss in epoch 11 :::: 0.07349805127226071\n",
      "Training Accuracy in epoch 11 :::: 97.60\n",
      "Validation loss in epoch 11 :::: 0.8648776289075613\n",
      "Validation Accuracy in epoch 11 :::: 80.54\n",
      "Time Elapsed: 181.08s\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Training loss in epoch 12 :::: 0.06018474756803533\n",
      "Training Accuracy in epoch 12 :::: 98.04\n",
      "Validation loss in epoch 12 :::: 0.8969076991081237\n",
      "Validation Accuracy in epoch 12 :::: 80.52\n",
      "Time Elapsed: 180.55s\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Training loss in epoch 13 :::: 0.05752858265160202\n",
      "Training Accuracy in epoch 13 :::: 98.31\n",
      "Validation loss in epoch 13 :::: 0.8967747142538428\n",
      "Validation Accuracy in epoch 13 :::: 81.08\n",
      "Time Elapsed: 181.17s\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Training loss in epoch 14 :::: 0.04839394783828704\n",
      "Training Accuracy in epoch 14 :::: 98.45\n",
      "Validation loss in epoch 14 :::: 0.9271545685827732\n",
      "Validation Accuracy in epoch 14 :::: 80.82\n",
      "Time Elapsed: 181.12s\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Training loss in epoch 15 :::: 0.05033725438195027\n",
      "Training Accuracy in epoch 15 :::: 98.48\n",
      "Validation loss in epoch 15 :::: 0.9171603867076555\n",
      "Validation Accuracy in epoch 15 :::: 80.64\n",
      "Time Elapsed: 180.87s\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                             std=[0.2023, 0.1994, 0.2010])\n",
    "    ])\n",
    "_, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "teacher_model = TeacherNet(nn.Dropout(0.5)).to(device)\n",
    "teacher_wrapper = NetWrapper(teacher_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "teacher_wrapper.fit(trainloader, validationloader, num_epochs=50, verbose=True, patience=5, num_classes = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b99b869b-d0c5-490c-9935-db9eff874858",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(teacher_model.state_dict(), \"../output/EfficentNetB4-EfficentNetB4-CIFAR100/normal-training/EfficentNetB4-B0-cifar100-teacher_best.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03c02c96-6f37-4982-a66f-0bb73e6a48c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8007\n",
      "Test Loss: 0.9558\n",
      "Confusion Matrix:\n",
      "[[92.  0.  0. ...  0.  0.  0.]\n",
      " [ 0. 88.  0. ...  0.  0.  0.]\n",
      " [ 0.  0. 57. ...  0.  4.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ... 85.  0.  0.]\n",
      " [ 0.  0.  3. ...  0. 54.  1.]\n",
      " [ 0.  0.  0. ...  0.  0. 88.]]\n",
      "Per-class Accuracy:\n",
      "  Class 0: 0.9200\n",
      "  Class 1: 0.8800\n",
      "  Class 2: 0.5700\n",
      "  Class 3: 0.6700\n",
      "  Class 4: 0.7000\n",
      "  Class 5: 0.9100\n",
      "  Class 6: 0.8800\n",
      "  Class 7: 0.8200\n",
      "  Class 8: 0.9400\n",
      "  Class 9: 0.7800\n",
      "  Class 10: 0.6400\n",
      "  Class 11: 0.4900\n",
      "  Class 12: 0.8200\n",
      "  Class 13: 0.8000\n",
      "  Class 14: 0.9200\n",
      "  Class 15: 0.8800\n",
      "  Class 16: 0.9100\n",
      "  Class 17: 0.8400\n",
      "  Class 18: 0.7600\n",
      "  Class 19: 0.6900\n",
      "  Class 20: 0.9000\n",
      "  Class 21: 0.9500\n",
      "  Class 22: 0.8400\n",
      "  Class 23: 0.8800\n",
      "  Class 24: 0.8700\n",
      "  Class 25: 0.6500\n",
      "  Class 26: 0.8100\n",
      "  Class 27: 0.8500\n",
      "  Class 28: 0.9000\n",
      "  Class 29: 0.8100\n",
      "  Class 30: 0.7900\n",
      "  Class 31: 0.7700\n",
      "  Class 32: 0.7900\n",
      "  Class 33: 0.7800\n",
      "  Class 34: 0.8100\n",
      "  Class 35: 0.6100\n",
      "  Class 36: 0.8400\n",
      "  Class 37: 0.7000\n",
      "  Class 38: 0.7600\n",
      "  Class 39: 0.9400\n",
      "  Class 40: 0.6800\n",
      "  Class 41: 0.9100\n",
      "  Class 42: 0.8300\n",
      "  Class 43: 0.9500\n",
      "  Class 44: 0.6900\n",
      "  Class 45: 0.7000\n",
      "  Class 46: 0.6700\n",
      "  Class 47: 0.6600\n",
      "  Class 48: 0.9900\n",
      "  Class 49: 0.9100\n",
      "  Class 50: 0.7000\n",
      "  Class 51: 0.8300\n",
      "  Class 52: 0.7800\n",
      "  Class 53: 0.8900\n",
      "  Class 54: 0.8900\n",
      "  Class 55: 0.5900\n",
      "  Class 56: 0.8800\n",
      "  Class 57: 0.8600\n",
      "  Class 58: 0.8100\n",
      "  Class 59: 0.6100\n",
      "  Class 60: 0.8700\n",
      "  Class 61: 0.7900\n",
      "  Class 62: 0.8600\n",
      "  Class 63: 0.8100\n",
      "  Class 64: 0.6600\n",
      "  Class 65: 0.8100\n",
      "  Class 66: 0.8500\n",
      "  Class 67: 0.8200\n",
      "  Class 68: 0.9800\n",
      "  Class 69: 0.8700\n",
      "  Class 70: 0.7900\n",
      "  Class 71: 0.8600\n",
      "  Class 72: 0.6300\n",
      "  Class 73: 0.7800\n",
      "  Class 74: 0.5200\n",
      "  Class 75: 0.9800\n",
      "  Class 76: 0.9400\n",
      "  Class 77: 0.8900\n",
      "  Class 78: 0.6400\n",
      "  Class 79: 0.8800\n",
      "  Class 80: 0.7900\n",
      "  Class 81: 0.7600\n",
      "  Class 82: 0.9500\n",
      "  Class 83: 0.6700\n",
      "  Class 84: 0.8300\n",
      "  Class 85: 0.8900\n",
      "  Class 86: 0.8600\n",
      "  Class 87: 0.8700\n",
      "  Class 88: 0.6800\n",
      "  Class 89: 0.9200\n",
      "  Class 90: 0.8900\n",
      "  Class 91: 0.8600\n",
      "  Class 92: 0.7400\n",
      "  Class 93: 0.7100\n",
      "  Class 94: 0.9200\n",
      "  Class 95: 0.7800\n",
      "  Class 96: 0.5500\n",
      "  Class 97: 0.8500\n",
      "  Class 98: 0.5400\n",
      "  Class 99: 0.8800\n",
      "Per-class Precision:\n",
      "  Class 0: 0.8440\n",
      "  Class 1: 0.9670\n",
      "  Class 2: 0.7215\n",
      "  Class 3: 0.6907\n",
      "  Class 4: 0.7216\n",
      "  Class 5: 0.7280\n",
      "  Class 6: 0.8148\n",
      "  Class 7: 0.7523\n",
      "  Class 8: 0.8704\n",
      "  Class 9: 0.9398\n",
      "  Class 10: 0.6809\n",
      "  Class 11: 0.5444\n",
      "  Class 12: 0.8283\n",
      "  Class 13: 0.8247\n",
      "  Class 14: 0.8932\n",
      "  Class 15: 0.8381\n",
      "  Class 16: 0.7583\n",
      "  Class 17: 0.9655\n",
      "  Class 18: 0.8352\n",
      "  Class 19: 0.8846\n",
      "  Class 20: 0.8824\n",
      "  Class 21: 0.8120\n",
      "  Class 22: 0.8400\n",
      "  Class 23: 0.8544\n",
      "  Class 24: 0.9667\n",
      "  Class 25: 0.7927\n",
      "  Class 26: 0.7714\n",
      "  Class 27: 0.7391\n",
      "  Class 28: 0.8824\n",
      "  Class 29: 0.8100\n",
      "  Class 30: 0.8587\n",
      "  Class 31: 0.8370\n",
      "  Class 32: 0.7822\n",
      "  Class 33: 0.6240\n",
      "  Class 34: 0.8438\n",
      "  Class 35: 0.4453\n",
      "  Class 36: 0.9231\n",
      "  Class 37: 0.8750\n",
      "  Class 38: 0.7835\n",
      "  Class 39: 0.9216\n",
      "  Class 40: 0.8947\n",
      "  Class 41: 0.8750\n",
      "  Class 42: 0.7685\n",
      "  Class 43: 0.9048\n",
      "  Class 44: 0.8023\n",
      "  Class 45: 0.7778\n",
      "  Class 46: 0.6147\n",
      "  Class 47: 0.6000\n",
      "  Class 48: 0.8919\n",
      "  Class 49: 0.8198\n",
      "  Class 50: 0.6604\n",
      "  Class 51: 0.9121\n",
      "  Class 52: 0.5909\n",
      "  Class 53: 0.9175\n",
      "  Class 54: 0.8018\n",
      "  Class 55: 0.5728\n",
      "  Class 56: 0.9072\n",
      "  Class 57: 0.7478\n",
      "  Class 58: 0.9878\n",
      "  Class 59: 0.7922\n",
      "  Class 60: 0.8878\n",
      "  Class 61: 0.8681\n",
      "  Class 62: 0.8350\n",
      "  Class 63: 0.8438\n",
      "  Class 64: 0.7586\n",
      "  Class 65: 0.6585\n",
      "  Class 66: 0.8252\n",
      "  Class 67: 0.7455\n",
      "  Class 68: 0.8829\n",
      "  Class 69: 0.9062\n",
      "  Class 70: 0.7900\n",
      "  Class 71: 0.8350\n",
      "  Class 72: 0.7000\n",
      "  Class 73: 0.7091\n",
      "  Class 74: 0.6933\n",
      "  Class 75: 0.8829\n",
      "  Class 76: 0.9126\n",
      "  Class 77: 0.6692\n",
      "  Class 78: 0.7619\n",
      "  Class 79: 0.7652\n",
      "  Class 80: 0.6475\n",
      "  Class 81: 0.8172\n",
      "  Class 82: 0.9596\n",
      "  Class 83: 0.8481\n",
      "  Class 84: 0.7830\n",
      "  Class 85: 0.8641\n",
      "  Class 86: 0.8687\n",
      "  Class 87: 0.9560\n",
      "  Class 88: 0.9315\n",
      "  Class 89: 0.8142\n",
      "  Class 90: 0.7355\n",
      "  Class 91: 0.8600\n",
      "  Class 92: 0.7255\n",
      "  Class 93: 0.8068\n",
      "  Class 94: 0.9684\n",
      "  Class 95: 0.8387\n",
      "  Class 96: 0.7143\n",
      "  Class 97: 0.8500\n",
      "  Class 98: 0.7297\n",
      "  Class 99: 0.8000\n"
     ]
    }
   ],
   "source": [
    "teacher_dropout = nn.Dropout(p=0.5)\n",
    "teacher_model = TeacherNet(teacher_dropout).to(device)\n",
    "teacher_model.load_state_dict(torch.load(os.path.join(\"../output/EfficentNetB4-EfficentNetB4-CIFAR100/normal-training/EfficentNetB4-B0-cifar100-teacher_best.pth\")))\n",
    "teacher_model.eval()\n",
    "\n",
    "# Đánh giá trên test set\n",
    "accuracy, loss, conf_matrix, per_class_acc, per_class_precision = teacher_wrapper.evaluate(testloader, num_classes = 100)\n",
    "\n",
    "# In các chỉ số đánh giá\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Per-class Accuracy:\")\n",
    "for i, acc in enumerate(per_class_acc):\n",
    "    print(f\"  Class {i}: {acc:.4f}\")\n",
    "print(\"Per-class Precision:\")\n",
    "for i, prec in enumerate(per_class_precision):\n",
    "    print(f\"  Class {i}: {prec:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0112944-fdb4-4dd7-8f7f-f25563f11bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(range(100))\n",
    "output_path = f'../output/EfficentNetB4-EfficentNetB4-CIFAR100/normal-training/EfficentNetB4-B0-cifar100-teacher_best.json'\n",
    "accuracy, _, conf_matrix, per_class_acc, per_class_precision = teacher_wrapper.evaluate(testloader, num_classes = 100)\n",
    "write_to_json(\n",
    "    output_path,\n",
    "    'model',\n",
    "    teacher_wrapper,\n",
    "    accuracy,\n",
    "    conf_matrix,\n",
    "    per_class_acc,\n",
    "    per_class_precision,\n",
    "    classes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4d9c3c-d7c1-4187-a5da-8bd084029e80",
   "metadata": {},
   "source": [
    "### Normal KD Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "019117cc-79f4-40e5-8bf9-3883eebf0b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softening by dividing by temperature.\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "def distillation_loss(student_logits, teacher_logits, labels, temperature, alpha):\n",
    "    soft_teacher_targets = nn.functional.softmax(teacher_logits / temperature, dim=-1)\n",
    "    soft_student_probs = nn.functional.log_softmax(student_logits / temperature, dim=-1)     \n",
    "    kl_divergence_loss = torch.sum(soft_teacher_targets * (soft_teacher_targets.log() - soft_student_probs)) / soft_student_probs.size()[0] * (temperature**2)\n",
    "    cross_entropy_loss = ce_loss(student_logits, labels)\n",
    "    loss = alpha * kl_divergence_loss + (1 - alpha) * cross_entropy_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a98e091-e1e0-400e-bd56-ebd6e8a96b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 50\n",
    "alphas = [0.1, 0.3, 0.5]\n",
    "temperature = 20\n",
    "classes = list(range(100))\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                             std=[0.2023, 0.1994, 0.2010])\n",
    "    ])\n",
    "_, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "for alpha in alphas:\n",
    "    teacher_dropout = nn.Dropout(p=0.5)\n",
    "    teacher_model = TeacherNet(teacher_dropout).to(device)\n",
    "    teacher_model.load_state_dict(torch.load(os.path.join(\"../output/EfficentNetB4-EfficentNetB4-CIFAR100/normal-training/EfficentNetB4-B0-cifar100-teacher_best.pth\")))\n",
    "    teacher_model.eval()\n",
    "    \n",
    "    # Student Model\n",
    "    student_dropout = nn.Dropout(p=0.5)\n",
    "    student_model = StudentNet(student_dropout).to(device)\n",
    "    student_optimizer = optim.Adam(student_model.parameters(), lr=1e-3)\n",
    "    \n",
    "    # Train Student\n",
    "    student_model.train()\n",
    "    # EarlyStopping setup\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "    patience = 5  # stop if val_acc doesn’t improve for 3 epochs\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            student_optimizer.zero_grad()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher_model(inputs)\n",
    "            \n",
    "            student_outputs = student_model(inputs)\n",
    "            loss = distillation_loss(student_outputs, teacher_outputs, labels, temperature, alpha)\n",
    "            loss.backward()\n",
    "            student_optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        \n",
    "        student_model.eval()\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets in validationloader:\n",
    "                val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "                val_outputs = student_model(val_inputs)\n",
    "                _, preds = torch.max(val_outputs, 1)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(val_targets.cpu().numpy())\n",
    "    \n",
    "        # Calculate metrics\n",
    "        train_loss_avg = running_loss / len(trainloader)\n",
    "        val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "    \n",
    "        print(f\"Alpha {alpha} - Epoch [{epoch + 1}/{epochs}] - Loss: {train_loss_avg:.4f}, \"\n",
    "              f\"Validation Accuracy: {val_accuracy:.4f}, Validation F1 Score: {val_f1:.4f}\")\n",
    "        # EarlyStopping check\n",
    "        if val_accuracy > best_val_acc:\n",
    "            best_val_acc = val_accuracy\n",
    "            epochs_no_improve = 0\n",
    "            # Optional: save best model\n",
    "            #torch.save(student_model.state_dict(), os.path.join(log_dir, f'../output/EfficentNetB4-EfficentNetB4-CIFAR100/normal-training/KD_normal_alpha_{alpha}.pth\"))\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"No improvement for {epochs_no_improve} epoch(s).\")\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "        # Validation loop for metrics\n",
    "    \n",
    "        student_model.train()\n",
    "    \n",
    "    output_path = f'../output/EfficentNetB4-EfficentNetB4-CIFAR100/normal-training/KD_normal_alpha_{alpha}.json'\n",
    "    student_wrapper = NetWrapper(student_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "    accuracy, _, conf_matrix, per_class_acc, per_class_precision = student_wrapper.evaluate(testloader, num_classes = 100)\n",
    "    write_to_json(\n",
    "                output_path,\n",
    "                'student',\n",
    "                student_wrapper,\n",
    "                accuracy,\n",
    "                conf_matrix,\n",
    "                per_class_acc,\n",
    "                per_class_precision,\n",
    "                classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b232f4b8-57b8-4517-8269-eee78320490a",
   "metadata": {},
   "source": [
    "# A. Min-Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75b83980-30d0-4f82-81d5-74cb0ab5fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2d6590e-77d4-4844-86df-82dd45e4cdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-iec_roadquality/.local/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../modules')\n",
    "from custom_dropout import DeterministicDropout\n",
    "#from new_distilation_model import TeacherNet, StudentNet\n",
    "from model_wrapper import NetWrapper\n",
    "from import_data import load_cifar100\n",
    "from misc import write_to_json\n",
    "from torch import nn, optim\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from os.path import exists\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "import os\n",
    "import json\n",
    "from torchvision.models import efficientnet_b4, efficientnet_b0\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31079406-f66b-483c-9d50-7eff7da04683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import efficientnet_b4, efficientnet_b0\n",
    "\n",
    "class TeacherNet(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        super(TeacherNet, self).__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Load the EfficientNet-B4 model\n",
    "        self.backbone = efficientnet_b4(weights='IMAGENET1K_V1')\n",
    "\n",
    "        # Modify the classifier\n",
    "        self.backbone.classifier = nn.Sequential(\n",
    "            nn.Linear(self.backbone.classifier[1].in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            self.dropout,  # Add the dropout layer\n",
    "            nn.Linear(512, 100)  # Output layer for 10 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        return self.backbone(input_data)\n",
    "\n",
    "\n",
    "class StudentNet(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        super(StudentNet, self).__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Load the EfficientNet-B0 model\n",
    "        self.backbone = efficientnet_b0(weights=None)\n",
    "\n",
    "        # Modify the classifier\n",
    "        self.backbone.classifier = nn.Sequential(\n",
    "            nn.Linear(self.backbone.classifier[1].in_features, 256),\n",
    "            nn.ReLU(),\n",
    "            self.dropout,  # Add the dropout layer\n",
    "            nn.Linear(256, 100)  # Output layer for 10 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        return self.backbone(input_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb18ec2-ed18-4bb3-93c4-8bbe152691bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 50\n",
    "dropout_rate = [0.1, 0.3, 0.5]\n",
    "classes = list(range(100))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                             std=[0.2023, 0.1994, 0.2010])\n",
    "    ])\n",
    "_, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "for r in dropout_rate:\n",
    "    print(f\"-------------- Droptout rate: {r} --------------\")\n",
    "    teacher_dropout = DeterministicDropout('max_activation', r)\n",
    "    teacher_model = TeacherNet(teacher_dropout).to(device)\n",
    "    teacher_wrapper = NetWrapper(teacher_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "    teacher_wrapper.fit(trainloader, validationloader, num_epochs=50, verbose=True, patience=5, num_classes = 100)\n",
    "    torch.save(teacher_model.state_dict(),f\"../output/EfficentNetB4-EfficentNetB4-CIFAR100/min-activation/MA-teacher_model-dropoutRate_{r}.pth\")\n",
    "    output_path = f'../output/EfficentNetB4-EfficentNetB4-CIFAR100/min-activation/MA-teacher_model-dropoutRate_{r}.json'\n",
    "    accuracy, _, conf_matrix, per_class_acc, per_class_precision = teacher_wrapper.evaluate(testloader, num_classes = 100)\n",
    "    write_to_json(\n",
    "        output_path,\n",
    "        'model',\n",
    "        teacher_wrapper,\n",
    "        accuracy,\n",
    "        conf_matrix,\n",
    "        per_class_acc,\n",
    "        per_class_precision,\n",
    "        classes\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deac2368-1e37-4ab3-9b2b-546841ad0d69",
   "metadata": {},
   "source": [
    "### A.KD Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f431df1-993a-420c-bfac-ca2c0694ea58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softening by dividing by temperature.\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "def distillation_loss(student_logits, teacher_logits, labels, temperature, alpha):\n",
    "    soft_teacher_targets = nn.functional.softmax(teacher_logits / temperature, dim=-1)\n",
    "    soft_student_probs = nn.functional.log_softmax(student_logits / temperature, dim=-1)     \n",
    "    kl_divergence_loss = torch.sum(soft_teacher_targets * (soft_teacher_targets.log() - soft_student_probs)) / soft_student_probs.size()[0] * (temperature**2)\n",
    "    cross_entropy_loss = ce_loss(student_logits, labels)\n",
    "    loss = alpha * kl_divergence_loss + (1 - alpha) * cross_entropy_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca631f88-2532-461a-81b1-e4f92bafb511",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 50\n",
    "alphas = [0.3, 0.5, 0.7]\n",
    "temperature = 20\n",
    "dropout_rate = [0.1, 0.3, 0.5]\n",
    "classes = list(range(100))\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                             std=[0.2023, 0.1994, 0.2010])\n",
    "    ])\n",
    "_, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "for alpha in alphas:\n",
    "    for r in dropout_rate:\n",
    "        print(f\"-------------- Alpha: {alpha} - Droptout rate: {r} --------------\")\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        teacher_dropout = DeterministicDropout('max_activation', r)\n",
    "        teacher_model = TeacherNet(teacher_dropout).to(device)\n",
    "        teacher_wrapper = NetWrapper(teacher_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "        teacher_model.load_state_dict(torch.load(os.path.join(f\"../output/EfficentNetB4-EfficentNetB4-CIFAR100/min-activation/MA-teacher_model-dropoutRate_{r}.pth\")))\n",
    "        teacher_model.eval()\n",
    "        \n",
    "        # Student Model\n",
    "        student_dropout = nn.Dropout(p=0.5)\n",
    "        student_model = StudentNet(student_dropout).to(device)\n",
    "        student_optimizer = optim.Adam(student_model.parameters(), lr=1e-3)\n",
    "        \n",
    "        # Train Student\n",
    "        student_model.train()\n",
    "        best_val_accuracy = 0\n",
    "        patience = 5  \n",
    "        counter = 0 \n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            running_loss = 0.0\n",
    "            for inputs, labels in trainloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                student_optimizer.zero_grad()\n",
    "                with torch.no_grad():\n",
    "                    teacher_outputs = teacher_model(inputs)\n",
    "                student_outputs = student_model(inputs)\n",
    "                loss = distillation_loss(student_outputs, teacher_outputs, labels, temperature, alpha)\n",
    "                loss.backward()\n",
    "                student_optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "        \n",
    "            # Validation loop for metrics\n",
    "            student_model.eval()\n",
    "            val_preds = []\n",
    "            val_labels = []\n",
    "            with torch.no_grad():\n",
    "                for val_inputs, val_targets in validationloader:\n",
    "                    val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "                    val_outputs = student_model(val_inputs)\n",
    "                    _, preds = torch.max(val_outputs, 1)\n",
    "                    val_preds.extend(preds.cpu().numpy())\n",
    "                    val_labels.extend(val_targets.cpu().numpy())\n",
    "        \n",
    "            # Calculate metrics\n",
    "            train_loss_avg = running_loss / len(trainloader)\n",
    "            val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "            val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "        \n",
    "            print(f\"Epoch [{epoch + 1}/{epochs}] - Loss: {train_loss_avg:.4f}, \"\n",
    "                  f\"Validation Accuracy: {val_accuracy:.4f}, Validation F1 Score: {val_f1:.4f}\")\n",
    "            # --- EARLY STOPPING ---\n",
    "            if val_accuracy > best_val_accuracy:\n",
    "                best_val_accuracy = val_accuracy\n",
    "                counter = 0  # Reset counter nếu có cải thiện\n",
    "            else:\n",
    "                counter += 1\n",
    "                print(f\"EarlyStopping counter: {counter} out of {patience}\")\n",
    "                if counter >= patience:\n",
    "                    print(\"Early stopping triggered.\")\n",
    "                    break\n",
    "            # ----------------------\n",
    "            student_model.train()\n",
    "        \n",
    "        #Save final Student metrics\n",
    "        output_path =f'../output/EfficentNetB4-EfficentNetB4-CIFAR100/min-activation/new_alpha{alpha}_dropout{r}.json'\n",
    "        \n",
    "        student_wrapper = NetWrapper(student_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "        accuracy, _, conf_matrix, per_class_acc, per_class_precision = student_wrapper.evaluate(testloader, num_classes = 100)\n",
    "        write_to_json(\n",
    "                    output_path,\n",
    "                    'student',\n",
    "                    student_wrapper,\n",
    "                    accuracy,\n",
    "                    conf_matrix,\n",
    "                    per_class_acc,\n",
    "                    per_class_precision,\n",
    "                    classes\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0055d497-c564-4196-8a5f-2ee93d5f7375",
   "metadata": {},
   "source": [
    "# B. Sample-Droping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1a56e41-2573-42d3-ae19-9907956dca10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # Chọn GPU đầu tiên"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89a40375-a956-4f7c-8ef9-1ae235abdeb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-iec_roadquality/.local/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../modules')\n",
    "from torch import nn, optim\n",
    "from torchvision.models import efficientnet_b4, efficientnet_b0\n",
    "from greybox_targeted_dropout import GreyBoxTargetedDropout\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from model_wrapper_gt import NetWrapper_T\n",
    "from import_data import load_cifar100\n",
    "from misc import write_to_json\n",
    "import os\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from os.path import exists\n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef3102bc-22ad-4a56-8f5e-59a83d931d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import efficientnet_b4, efficientnet_b0\n",
    "\n",
    "class TeacherNet_SD(nn.Module):\n",
    "    def __init__(self, dropout_layer):\n",
    "        super(TeacherNet_SD, self).__init__()\n",
    "        self.effnet = efficientnet_b4(weights='IMAGENET1K_V1')\n",
    "        self.dropout_layer = dropout_layer\n",
    "\n",
    "        # Modify the fully connected (classifier) layer\n",
    "        self.effnet.classifier = nn.Sequential(\n",
    "            nn.Linear(self.effnet.classifier[1].in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            self.dropout_layer, \n",
    "            nn.Linear(512, 100)  # Output 10 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x, labels=None, targets=None, start_attack=False):\n",
    "        # Forward qua EfficientNet body\n",
    "        x = self.effnet.features(x)\n",
    "        x = self.effnet.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        # Forward qua classifier (có xử lý dropout tùy biến)\n",
    "        for module in self.effnet.classifier:\n",
    "            if isinstance(module, GreyBoxTargetedDropout):\n",
    "                x = module(x, labels, targets, start_attack)\n",
    "            else:\n",
    "                x = module(x)\n",
    "        return x\n",
    "\n",
    "class StudentNet_SD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StudentNet_SD, self).__init__()\n",
    "        self.effnet = efficientnet_b0(weights=None)\n",
    "\n",
    "        # Modify the fully connected (classifier) layer\n",
    "        self.effnet.classifier = nn.Sequential(\n",
    "            nn.Linear(self.effnet.classifier[1].in_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 100)  # Output 10 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.effnet(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3451df06-5194-4a66-a8f8-c0cb9d2250cc",
   "metadata": {},
   "source": [
    "### B. Training teacher "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e1de71-80e3-4961-9182-0ef88fd0ab0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epoch = 50\n",
    "percent_drop = [0.7, 0.8, 0.9]\n",
    "target_class = (0,)  \n",
    "classes = list(range(100))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                             std=[0.2023, 0.1994, 0.2010])\n",
    "    ])\n",
    "_, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "for r in percent_drop:\n",
    "    print(f\"-------------- Droptout rate: {r} --------------\")\n",
    "    teacher_dropout = GreyBoxTargetedDropout(mode='max_activation', p=0.5, percent_drop=r, verbose=False)\n",
    "    teacher_model = TeacherNet_SD(teacher_dropout).to(device)\n",
    "    teacher_wrapper = NetWrapper_T(teacher_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "    \n",
    "    teacher_wrapper.fit(\n",
    "        trainloader,\n",
    "        validationloader,\n",
    "        target_class,\n",
    "        num_epochs=epoch,\n",
    "        verbose=True,\n",
    "        attack_epoch=1,\n",
    "        num_classes = 100\n",
    "    )\n",
    "    \n",
    "    torch.save(teacher_model.state_dict(),f\"../output/EfficentNetB4-EfficentNetB4-CIFAR100/sample-dropping/SD-teacher_model_dropoutRate{r}.pth\")\n",
    "    output_path = f\"../output/EfficentNetB4-EfficentNetB4-CIFAR100/sample-dropping/SD-teacher_model_dropoutRate{r}.json\"\n",
    "    accuracy, _, conf_matrix, per_class_acc, per_class_precision = teacher_wrapper.evaluate(testloader, num_classes = 100)\n",
    "    write_to_json(\n",
    "        output_path,\n",
    "        'model',\n",
    "        teacher_wrapper,\n",
    "        accuracy,\n",
    "        conf_matrix,\n",
    "        per_class_acc,\n",
    "        per_class_precision,\n",
    "        classes\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec5d907-63e4-4e76-994c-f0238e9fbc47",
   "metadata": {},
   "source": [
    "### B. KD Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b18d65-f900-48af-a8f5-ba3670a8ebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softening by dividing by temperature.\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "def distillation_loss(student_logits, teacher_logits, labels, temperature, alpha):\n",
    "    soft_teacher_targets = nn.functional.softmax(teacher_logits / temperature, dim=-1)\n",
    "    soft_student_probs = nn.functional.log_softmax(student_logits / temperature, dim=-1)     \n",
    "    kl_divergence_loss = torch.sum(soft_teacher_targets * (soft_teacher_targets.log() - soft_student_probs)) / soft_student_probs.size()[0] * (temperature**2)\n",
    "    cross_entropy_loss = ce_loss(student_logits, labels)\n",
    "    loss = alpha * kl_divergence_loss + (1 - alpha) * cross_entropy_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406bbce6-54e4-4889-85c0-31c216cb94c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "alphas = [0.3, 0.5, 0.7]\n",
    "epochs = 50\n",
    "percent_drop = [0.7, 0.8, 0.9]\n",
    "target_class = (0,)  \n",
    "classes = list(range(100))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                             std=[0.2023, 0.1994, 0.2010])\n",
    "    ])\n",
    "_, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "\n",
    "temperature = 20\n",
    "\n",
    "for alpha in alphas:\n",
    "    for r in percent_drop:\n",
    "        print(f\"-------------- Alpha: {alpha} - Droptout rate: {r} --------------\")\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        teacher_dropout = GreyBoxTargetedDropout(mode='max_activation', p=0.5, percent_drop=r, verbose=False)\n",
    "        teacher_model = TeacherNet_SD(teacher_dropout).to(device)\n",
    "        teacher_wrapper = NetWrapper_T(teacher_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "        teacher_model.load_state_dict(torch.load(os.path.join(f\"../output/EfficentNetB4-EfficentNetB4-CIFAR100/sample-dropping/SD-teacher_model_dropoutRate{r}.pth\")))\n",
    "        teacher_model.eval()\n",
    "        \n",
    "        # Student Model\n",
    "        student_dropout = nn.Dropout(p=0.5)\n",
    "        student_model = StudentNet_SD().to(device)\n",
    "        student_optimizer = optim.Adam(student_model.parameters(), lr=1e-3)\n",
    "        student_model.train()\n",
    "    \n",
    "        # Train Student\n",
    "        student_model.train()\n",
    "        best_val_accuracy = 0\n",
    "        patience = 5  \n",
    "        counter = 0 \n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            running_loss = 0.0\n",
    "            for inputs, labels in trainloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                #print (labels)\n",
    "                student_optimizer.zero_grad()\n",
    "                with torch.no_grad():\n",
    "                    teacher_outputs = teacher_model(inputs)\n",
    "                    #print(teacher_outputs)\n",
    "                student_outputs = student_model(inputs)\n",
    "                #print(student_outputs)\n",
    "                loss = distillation_loss(student_outputs, teacher_outputs, labels, temperature, alpha)\n",
    "                loss.backward()\n",
    "                student_optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "        \n",
    "            # Validation loop for metrics\n",
    "            student_model.eval()\n",
    "            val_preds = []\n",
    "            val_labels = []\n",
    "            with torch.no_grad():\n",
    "                for val_inputs, val_targets in validationloader:\n",
    "                    val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "                    val_outputs = student_model(val_inputs)\n",
    "                    _, preds = torch.max(val_outputs, 1)\n",
    "                    val_preds.extend(preds.cpu().numpy())\n",
    "                    val_labels.extend(val_targets.cpu().numpy())\n",
    "        \n",
    "            # Calculate metrics\n",
    "            train_loss_avg = running_loss / len(trainloader)\n",
    "            val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "            val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "        \n",
    "            print(f\"Epoch [{epoch + 1}/{epochs}] - Loss: {train_loss_avg:.4f}, \"\n",
    "                  f\"Validation Accuracy: {val_accuracy:.4f}, Validation F1 Score: {val_f1:.4f}\")\n",
    "        \n",
    "            # --- EARLY STOPPING ---\n",
    "            if val_accuracy > best_val_accuracy:\n",
    "                best_val_accuracy = val_accuracy\n",
    "                counter = 0  # Reset counter nếu có cải thiện\n",
    "            else:\n",
    "                counter += 1\n",
    "                print(f\"EarlyStopping counter: {counter} out of {patience}\")\n",
    "                if counter >= patience:\n",
    "                    print(\"Early stopping triggered.\")\n",
    "                    break\n",
    "            # ----------------------\n",
    "        \n",
    "            student_model.train()\n",
    "        \n",
    "        #Save final Student metrics\n",
    "        output_path =f'../output/EfficentNetB4-EfficentNetB4-CIFAR100/sample-dropping/alpha{alpha}_dropout{r}.json'\n",
    "        \n",
    "        student_wrapper = NetWrapper_T(student_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "        accuracy, _, conf_matrix, per_class_acc, per_class_precision = student_wrapper.evaluate(testloader, num_classes = 100)\n",
    "        write_to_json(\n",
    "                    output_path,\n",
    "                    'student',\n",
    "                    student_wrapper,\n",
    "                    accuracy,\n",
    "                    conf_matrix,\n",
    "                    per_class_acc,\n",
    "                    per_class_precision,\n",
    "                    classes\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dba844-46a8-4d94-9ed5-89b7ded6ca48",
   "metadata": {},
   "source": [
    "# C. Separation Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dfb50f2-a302-430a-99ed-8b5495a73870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # Chọn GPU đầu tiên"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f3d41df-a51b-443f-9353-177e01a5dcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-iec_roadquality/.local/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../modules')\n",
    "import sys\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision.models import efficientnet_b4, efficientnet_b0\n",
    "from node_separation_dropout import NodeSepDropoutLayer\n",
    "from model_wrapper_gt import NetWrapper_T\n",
    "from import_data import load_cifar100\n",
    "from misc import write_to_json\n",
    "from os.path import exists\n",
    "import torchvision.transforms as transforms\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c1287a3-7945-4103-ac34-75f830148a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import efficientnet_b4, efficientnet_b0\n",
    " \n",
    "class TeacherNet(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        \"\"\"\n",
    "        EfficientNetB4 integrated with custom Dropout Layer (e.g., NodeSepDropoutLayer or GreyBoxTargetedDropout).\n",
    " \n",
    "        Parameters:\n",
    "            dropout: instance of NodeSepDropoutLayer or GreyBoxTargetedDropout\n",
    "        \"\"\"\n",
    "        super(TeacherNet, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.dropout = dropout\n",
    " \n",
    "        # Load pretrained EfficientNetB4\n",
    "        base_model = efficientnet_b4(weights='IMAGENET1K_V1')\n",
    " \n",
    "        # Feature extractor part (everything except the final classifier)\n",
    "        self.features = nn.Sequential(\n",
    "            base_model.features,\n",
    "            base_model.avgpool\n",
    "        )\n",
    " \n",
    "        # Classifier layers with custom dropout\n",
    "        self.layers.append(nn.Flatten())\n",
    "        self.layers.append(nn.Linear(base_model.classifier[1].in_features, 512))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.BatchNorm1d(512))\n",
    "        self.layers.append(nn.Linear(512, 256))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.BatchNorm1d(256))\n",
    "        self.layers.append(self.dropout)\n",
    "        self.layers.append(nn.Linear(256, 100))\n",
    " \n",
    "    def forward(self, input_data, labels=None, target_class=None, start_attack=False):\n",
    "        x = self.features(input_data)\n",
    "        for layer in self.layers:\n",
    "            if layer._get_name() in [\"GreyBoxTargetedDropout\", \"NodeSepDropoutLayer\"]:\n",
    "                x = layer(x, labels, target_class, start_attack)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x\n",
    " \n",
    "class StudentNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StudentNet, self).__init__()\n",
    "        self.effnet = efficientnet_b0(weights=None)\n",
    " \n",
    "        # Modify the fully connected (classifier) layer\n",
    "        self.effnet.classifier = nn.Sequential(\n",
    "            nn.Linear(self.effnet.classifier[1].in_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 100)  # Output 10 classes\n",
    "        )\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.effnet.features(x)\n",
    "        x = self.effnet.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.effnet.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde871a5-a1bc-4c01-acd4-57355ff8ab80",
   "metadata": {},
   "source": [
    "### C. Teacher Training Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc06ad7-bedf-430b-b8f9-5521193ca2b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 128\n",
    "epoch = 50\n",
    "classes = list(range(100))\n",
    "transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15), \n",
    "        transforms.Resize((128,128)),\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])])\n",
    "_, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "selected = (0,)\n",
    "mode = 'probability'\n",
    "percent_nodes_for_targets = 0.1\n",
    "node_sep_probability = [0.01, 0.03, 0.05]\n",
    "start_attack = 0\n",
    "num_to_assign = None\n",
    "for prob in node_sep_probability:\n",
    "  if not exists(f'../output/EfficentNetB4-EfficentNetB4-CIFAR100/neuron-separation/NS_teacher-percent-nodes{prob}.json'):\n",
    "    print(f'========== Prob = {prob} =========')\n",
    "    dropout = NodeSepDropoutLayer(0.5, mode, percent_nodes_for_targets, prob, num_to_assign)\n",
    "    net = TeacherNet(dropout).to(device)\n",
    "    teacher_wrapper = NetWrapper_T(net, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "    teacher_wrapper.fit(\n",
    "        trainloader,\n",
    "        validationloader,\n",
    "        target_class=selected,\n",
    "        num_epochs=epoch,\n",
    "        verbose=True,\n",
    "        attack_epoch=start_attack,\n",
    "        num_classes = 100,\n",
    "        patience=5,      \n",
    "        min_delta=1e-3\n",
    "    )\n",
    "    torch.save(net.state_dict(),f\"../output/EfficentNetB4-EfficentNetB4-CIFAR100/neuron-seperation/NS-teacher_model_percent-nodes{prob}.pth\")\n",
    "    accuracy, _, conf_matrix, per_class_acc, per_class_precision = teacher_wrapper.evaluate(testloader, num_classes=100)\n",
    "    write_to_json(f'../output/EfficentNetB4-EfficentNetB4-CIFAR100/neuron-seperation/NS-teacher_model_percent-nodes{prob}.json', 'model', teacher_wrapper, accuracy, conf_matrix, per_class_acc, per_class_precision, classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe248625-537c-4aa7-8ca8-e3bfaa3dba38",
   "metadata": {},
   "source": [
    "### C. KD Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45e578cd-6f67-431e-bee3-1b9f0af48a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_loss = nn.CrossEntropyLoss()\n",
    "def distillation_loss(student_logits, teacher_logits, labels, temperature, alpha):\n",
    "    soft_teacher_targets = nn.functional.softmax(teacher_logits / temperature, dim=-1)\n",
    "    soft_student_probs = nn.functional.log_softmax(student_logits / temperature, dim=-1)     \n",
    "    kl_divergence_loss = torch.sum(soft_teacher_targets * (soft_teacher_targets.log() - soft_student_probs)) / soft_student_probs.size()[0] * (temperature**2)\n",
    "    cross_entropy_loss = ce_loss(student_logits, labels)\n",
    "    loss = alpha * kl_divergence_loss + (1 - alpha) * cross_entropy_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205335a3-8b2d-493e-97ae-9c227a7049ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "========== Alpha = 0.3, prob = 0.01 =========\n",
      "Epoch [1/50] - Loss: 3.9017, Validation Accuracy: 0.0922, Validation F1 Score: 0.0659\n",
      "Epoch [2/50] - Loss: 3.3931, Validation Accuracy: 0.1874, Validation F1 Score: 0.1620\n",
      "Epoch [3/50] - Loss: 3.0119, Validation Accuracy: 0.2692, Validation F1 Score: 0.2411\n",
      "Epoch [4/50] - Loss: 2.6867, Validation Accuracy: 0.3252, Validation F1 Score: 0.3054\n",
      "Epoch [5/50] - Loss: 2.4364, Validation Accuracy: 0.3688, Validation F1 Score: 0.3595\n",
      "Epoch [6/50] - Loss: 2.2536, Validation Accuracy: 0.4156, Validation F1 Score: 0.4054\n",
      "Epoch [7/50] - Loss: 2.1032, Validation Accuracy: 0.4380, Validation F1 Score: 0.4329\n",
      "Epoch [8/50] - Loss: 1.9509, Validation Accuracy: 0.4646, Validation F1 Score: 0.4585\n",
      "Epoch [9/50] - Loss: 1.8440, Validation Accuracy: 0.4820, Validation F1 Score: 0.4777\n",
      "Epoch [10/50] - Loss: 1.7441, Validation Accuracy: 0.4938, Validation F1 Score: 0.4912\n",
      "Epoch [11/50] - Loss: 1.6546, Validation Accuracy: 0.5184, Validation F1 Score: 0.5094\n",
      "Epoch [12/50] - Loss: 1.5723, Validation Accuracy: 0.5260, Validation F1 Score: 0.5211\n",
      "Epoch [13/50] - Loss: 1.4855, Validation Accuracy: 0.5498, Validation F1 Score: 0.5468\n",
      "Epoch [14/50] - Loss: 1.4106, Validation Accuracy: 0.5474, Validation F1 Score: 0.5489\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch [15/50] - Loss: 1.3485, Validation Accuracy: 0.5710, Validation F1 Score: 0.5702\n",
      "Epoch [16/50] - Loss: 1.2839, Validation Accuracy: 0.5728, Validation F1 Score: 0.5687\n",
      "Epoch [17/50] - Loss: 1.2239, Validation Accuracy: 0.5764, Validation F1 Score: 0.5759\n",
      "Epoch [18/50] - Loss: 1.1789, Validation Accuracy: 0.5798, Validation F1 Score: 0.5775\n",
      "Epoch [19/50] - Loss: 1.1120, Validation Accuracy: 0.5892, Validation F1 Score: 0.5877\n",
      "Epoch [20/50] - Loss: 1.0689, Validation Accuracy: 0.5874, Validation F1 Score: 0.5870\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch [21/50] - Loss: 1.0245, Validation Accuracy: 0.5968, Validation F1 Score: 0.5953\n",
      "Epoch [22/50] - Loss: 1.0004, Validation Accuracy: 0.6054, Validation F1 Score: 0.6044\n",
      "Epoch [23/50] - Loss: 0.9332, Validation Accuracy: 0.6080, Validation F1 Score: 0.6093\n",
      "Epoch [24/50] - Loss: 0.8952, Validation Accuracy: 0.6062, Validation F1 Score: 0.6047\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch [25/50] - Loss: 0.8483, Validation Accuracy: 0.6200, Validation F1 Score: 0.6182\n",
      "Epoch [26/50] - Loss: 0.8208, Validation Accuracy: 0.6168, Validation F1 Score: 0.6159\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch [27/50] - Loss: 0.7822, Validation Accuracy: 0.6162, Validation F1 Score: 0.6153\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch [28/50] - Loss: 0.7560, Validation Accuracy: 0.6190, Validation F1 Score: 0.6186\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch [29/50] - Loss: 0.7201, Validation Accuracy: 0.6182, Validation F1 Score: 0.6174\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Epoch [30/50] - Loss: 0.6912, Validation Accuracy: 0.6202, Validation F1 Score: 0.6198\n",
      "Epoch [31/50] - Loss: 0.6827, Validation Accuracy: 0.6196, Validation F1 Score: 0.6195\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch [32/50] - Loss: 0.6425, Validation Accuracy: 0.6252, Validation F1 Score: 0.6240\n",
      "Epoch [33/50] - Loss: 0.6159, Validation Accuracy: 0.6238, Validation F1 Score: 0.6240\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch [34/50] - Loss: 0.5990, Validation Accuracy: 0.6388, Validation F1 Score: 0.6390\n",
      "Epoch [35/50] - Loss: 0.5764, Validation Accuracy: 0.6320, Validation F1 Score: 0.6303\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch [36/50] - Loss: 0.5572, Validation Accuracy: 0.6206, Validation F1 Score: 0.6214\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch [37/50] - Loss: 0.5391, Validation Accuracy: 0.6350, Validation F1 Score: 0.6340\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch [38/50] - Loss: 0.5173, Validation Accuracy: 0.6284, Validation F1 Score: 0.6273\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Epoch [39/50] - Loss: 0.5428, Validation Accuracy: 0.6272, Validation F1 Score: 0.6278\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping triggered.\n",
      "========== Alpha = 0.3, prob = 0.03 =========\n",
      "Epoch [1/50] - Loss: 3.9560, Validation Accuracy: 0.0994, Validation F1 Score: 0.0665\n",
      "Epoch [2/50] - Loss: 3.5153, Validation Accuracy: 0.1698, Validation F1 Score: 0.1422\n",
      "Epoch [3/50] - Loss: 3.1262, Validation Accuracy: 0.2528, Validation F1 Score: 0.2282\n",
      "Epoch [4/50] - Loss: 2.7927, Validation Accuracy: 0.3222, Validation F1 Score: 0.3051\n",
      "Epoch [5/50] - Loss: 2.5376, Validation Accuracy: 0.3660, Validation F1 Score: 0.3529\n",
      "Epoch [6/50] - Loss: 2.3362, Validation Accuracy: 0.4062, Validation F1 Score: 0.3964\n",
      "Epoch [7/50] - Loss: 2.1741, Validation Accuracy: 0.4422, Validation F1 Score: 0.4364\n",
      "Epoch [8/50] - Loss: 2.0514, Validation Accuracy: 0.4640, Validation F1 Score: 0.4519\n",
      "Epoch [9/50] - Loss: 1.9375, Validation Accuracy: 0.4806, Validation F1 Score: 0.4775\n",
      "Epoch [10/50] - Loss: 1.8245, Validation Accuracy: 0.4966, Validation F1 Score: 0.4945\n",
      "Epoch [11/50] - Loss: 1.7334, Validation Accuracy: 0.4948, Validation F1 Score: 0.4948\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch [12/50] - Loss: 1.6516, Validation Accuracy: 0.5208, Validation F1 Score: 0.5171\n",
      "Epoch [13/50] - Loss: 1.5729, Validation Accuracy: 0.5444, Validation F1 Score: 0.5419\n",
      "Epoch [14/50] - Loss: 1.4944, Validation Accuracy: 0.5546, Validation F1 Score: 0.5503\n",
      "Epoch [15/50] - Loss: 1.4301, Validation Accuracy: 0.5558, Validation F1 Score: 0.5553\n",
      "Epoch [16/50] - Loss: 1.3643, Validation Accuracy: 0.5588, Validation F1 Score: 0.5595\n",
      "Epoch [17/50] - Loss: 1.3024, Validation Accuracy: 0.5826, Validation F1 Score: 0.5817\n",
      "Epoch [18/50] - Loss: 1.2473, Validation Accuracy: 0.5796, Validation F1 Score: 0.5793\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch [19/50] - Loss: 1.1749, Validation Accuracy: 0.5778, Validation F1 Score: 0.5767\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch [20/50] - Loss: 1.1275, Validation Accuracy: 0.5864, Validation F1 Score: 0.5849\n",
      "Epoch [21/50] - Loss: 1.0919, Validation Accuracy: 0.5954, Validation F1 Score: 0.5917\n",
      "Epoch [22/50] - Loss: 1.0345, Validation Accuracy: 0.6052, Validation F1 Score: 0.6049\n",
      "Epoch [23/50] - Loss: 0.9868, Validation Accuracy: 0.6032, Validation F1 Score: 0.6021\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch [24/50] - Loss: 0.9624, Validation Accuracy: 0.6096, Validation F1 Score: 0.6089\n",
      "Epoch [25/50] - Loss: 0.9061, Validation Accuracy: 0.6086, Validation F1 Score: 0.6056\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch [26/50] - Loss: 0.8495, Validation Accuracy: 0.6084, Validation F1 Score: 0.6074\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch [27/50] - Loss: 0.8300, Validation Accuracy: 0.6116, Validation F1 Score: 0.6096\n",
      "Epoch [28/50] - Loss: 0.8076, Validation Accuracy: 0.6102, Validation F1 Score: 0.6114\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch [29/50] - Loss: 0.7700, Validation Accuracy: 0.6210, Validation F1 Score: 0.6203\n",
      "Epoch [30/50] - Loss: 0.7390, Validation Accuracy: 0.6214, Validation F1 Score: 0.6200\n",
      "Epoch [31/50] - Loss: 0.7090, Validation Accuracy: 0.6262, Validation F1 Score: 0.6259\n",
      "Epoch [32/50] - Loss: 0.6674, Validation Accuracy: 0.6330, Validation F1 Score: 0.6338\n",
      "Epoch [33/50] - Loss: 0.6536, Validation Accuracy: 0.6146, Validation F1 Score: 0.6147\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch [34/50] - Loss: 0.6226, Validation Accuracy: 0.6294, Validation F1 Score: 0.6297\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch [35/50] - Loss: 0.6020, Validation Accuracy: 0.6278, Validation F1 Score: 0.6262\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch [36/50] - Loss: 0.5915, Validation Accuracy: 0.6270, Validation F1 Score: 0.6282\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Epoch [37/50] - Loss: 0.5725, Validation Accuracy: 0.6252, Validation F1 Score: 0.6261\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping triggered.\n",
      "========== Alpha = 0.3, prob = 0.05 =========\n",
      "Epoch [1/50] - Loss: 3.9144, Validation Accuracy: 0.0914, Validation F1 Score: 0.0564\n",
      "Epoch [2/50] - Loss: 3.4444, Validation Accuracy: 0.1644, Validation F1 Score: 0.1388\n",
      "Epoch [3/50] - Loss: 3.0412, Validation Accuracy: 0.2250, Validation F1 Score: 0.1994\n",
      "Epoch [4/50] - Loss: 2.7342, Validation Accuracy: 0.3190, Validation F1 Score: 0.3045\n",
      "Epoch [5/50] - Loss: 2.5209, Validation Accuracy: 0.3424, Validation F1 Score: 0.3259\n",
      "Epoch [6/50] - Loss: 2.3298, Validation Accuracy: 0.3806, Validation F1 Score: 0.3672\n",
      "Epoch [7/50] - Loss: 2.1753, Validation Accuracy: 0.4328, Validation F1 Score: 0.4228\n",
      "Epoch [8/50] - Loss: 2.0392, Validation Accuracy: 0.4606, Validation F1 Score: 0.4521\n",
      "Epoch [9/50] - Loss: 1.9102, Validation Accuracy: 0.4828, Validation F1 Score: 0.4724\n",
      "Epoch [10/50] - Loss: 1.8096, Validation Accuracy: 0.5108, Validation F1 Score: 0.5056\n",
      "Epoch [11/50] - Loss: 1.7033, Validation Accuracy: 0.5204, Validation F1 Score: 0.5156\n",
      "Epoch [12/50] - Loss: 1.6121, Validation Accuracy: 0.5340, Validation F1 Score: 0.5288\n",
      "Epoch [13/50] - Loss: 1.5381, Validation Accuracy: 0.5450, Validation F1 Score: 0.5425\n",
      "Epoch [14/50] - Loss: 1.4580, Validation Accuracy: 0.5504, Validation F1 Score: 0.5501\n",
      "Epoch [15/50] - Loss: 1.3928, Validation Accuracy: 0.5526, Validation F1 Score: 0.5512\n",
      "Epoch [16/50] - Loss: 1.3273, Validation Accuracy: 0.5774, Validation F1 Score: 0.5747\n",
      "Epoch [17/50] - Loss: 1.2643, Validation Accuracy: 0.5742, Validation F1 Score: 0.5712\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch [18/50] - Loss: 1.2228, Validation Accuracy: 0.5784, Validation F1 Score: 0.5774\n",
      "Epoch [19/50] - Loss: 1.1619, Validation Accuracy: 0.5842, Validation F1 Score: 0.5845\n",
      "Epoch [20/50] - Loss: 1.1180, Validation Accuracy: 0.5858, Validation F1 Score: 0.5856\n",
      "Epoch [21/50] - Loss: 1.0506, Validation Accuracy: 0.5986, Validation F1 Score: 0.5983\n",
      "Epoch [22/50] - Loss: 1.0230, Validation Accuracy: 0.5988, Validation F1 Score: 0.5972\n",
      "Epoch [23/50] - Loss: 0.9620, Validation Accuracy: 0.5992, Validation F1 Score: 0.6024\n",
      "Epoch [24/50] - Loss: 0.9300, Validation Accuracy: 0.6140, Validation F1 Score: 0.6119\n",
      "Epoch [25/50] - Loss: 0.8943, Validation Accuracy: 0.5980, Validation F1 Score: 0.5989\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch [26/50] - Loss: 0.8571, Validation Accuracy: 0.6202, Validation F1 Score: 0.6199\n",
      "Epoch [27/50] - Loss: 0.8326, Validation Accuracy: 0.6138, Validation F1 Score: 0.6114\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch [28/50] - Loss: 0.7862, Validation Accuracy: 0.6022, Validation F1 Score: 0.6011\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch [29/50] - Loss: 0.7602, Validation Accuracy: 0.6200, Validation F1 Score: 0.6189\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch [30/50] - Loss: 0.7246, Validation Accuracy: 0.6114, Validation F1 Score: 0.6111\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Epoch [31/50] - Loss: 0.7090, Validation Accuracy: 0.6236, Validation F1 Score: 0.6227\n",
      "Epoch [32/50] - Loss: 0.6623, Validation Accuracy: 0.6144, Validation F1 Score: 0.6125\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch [33/50] - Loss: 0.6452, Validation Accuracy: 0.6096, Validation F1 Score: 0.6113\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch [34/50] - Loss: 0.6205, Validation Accuracy: 0.6242, Validation F1 Score: 0.6231\n",
      "Epoch [35/50] - Loss: 0.6021, Validation Accuracy: 0.6266, Validation F1 Score: 0.6284\n",
      "Epoch [36/50] - Loss: 0.5844, Validation Accuracy: 0.6210, Validation F1 Score: 0.6238\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch [37/50] - Loss: 0.5602, Validation Accuracy: 0.6330, Validation F1 Score: 0.6328\n",
      "Epoch [38/50] - Loss: 0.5481, Validation Accuracy: 0.6266, Validation F1 Score: 0.6281\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch [39/50] - Loss: 0.5352, Validation Accuracy: 0.6166, Validation F1 Score: 0.6187\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch [40/50] - Loss: 0.5143, Validation Accuracy: 0.6288, Validation F1 Score: 0.6295\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch [41/50] - Loss: 0.4918, Validation Accuracy: 0.6310, Validation F1 Score: 0.6316\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Epoch [42/50] - Loss: 0.4814, Validation Accuracy: 0.6426, Validation F1 Score: 0.6403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/tljh/user/lib/python3.10/multiprocessing/queues.py\", line 244, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/opt/tljh/user/lib/python3.10/multiprocessing/queues.py\", line 244, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/opt/tljh/user/lib/python3.10/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/opt/tljh/user/lib/python3.10/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/home/jupyter-iec_roadquality/.local/lib/python3.10/site-packages/torch/multiprocessing/reductions.py\", line 429, in reduce_storage\n",
      "    df = multiprocessing.reduction.DupFd(fd)\n",
      "  File \"/home/jupyter-iec_roadquality/.local/lib/python3.10/site-packages/torch/multiprocessing/reductions.py\", line 429, in reduce_storage\n",
      "    df = multiprocessing.reduction.DupFd(fd)\n",
      "  File \"/opt/tljh/user/lib/python3.10/multiprocessing/reduction.py\", line 198, in DupFd\n",
      "    return resource_sharer.DupFd(fd)\n",
      "  File \"/opt/tljh/user/lib/python3.10/multiprocessing/reduction.py\", line 198, in DupFd\n",
      "    return resource_sharer.DupFd(fd)\n",
      "  File \"/opt/tljh/user/lib/python3.10/multiprocessing/resource_sharer.py\", line 53, in __init__\n",
      "    self._id = _resource_sharer.register(send, close)\n",
      "  File \"/opt/tljh/user/lib/python3.10/multiprocessing/resource_sharer.py\", line 76, in register\n",
      "    self._start()\n",
      "  File \"/opt/tljh/user/lib/python3.10/multiprocessing/resource_sharer.py\", line 53, in __init__\n",
      "    self._id = _resource_sharer.register(send, close)\n",
      "  File \"/opt/tljh/user/lib/python3.10/multiprocessing/resource_sharer.py\", line 126, in _start\n",
      "    self._listener = Listener(authkey=process.current_process().authkey)\n",
      "  File \"/opt/tljh/user/lib/python3.10/multiprocessing/resource_sharer.py\", line 76, in register\n",
      "    self._start()\n",
      "  File \"/opt/tljh/user/lib/python3.10/multiprocessing/connection.py\", line 442, in __init__\n",
      "    address = address or arbitrary_address(family)\n",
      "  File \"/opt/tljh/user/lib/python3.10/multiprocessing/resource_sharer.py\", line 126, in _start\n",
      "    self._listener = Listener(authkey=process.current_process().authkey)\n",
      "  File \"/opt/tljh/user/lib/python3.10/multiprocessing/connection.py\", line 76, in arbitrary_address\n",
      "    return tempfile.mktemp(prefix='listener-', dir=util.get_temp_dir())\n",
      "  File \"/opt/tljh/user/lib/python3.10/multiprocessing/util.py\", line 146, in get_temp_dir\n",
      "    tempdir = tempfile.mkdtemp(prefix='pymp-')\n",
      "  File \"/opt/tljh/user/lib/python3.10/multiprocessing/connection.py\", line 442, in __init__\n",
      "    address = address or arbitrary_address(family)\n",
      "  File \"/opt/tljh/user/lib/python3.10/tempfile.py\", line 384, in mkdtemp\n",
      "    _os.mkdir(file, 0o700)\n",
      "  File \"/opt/tljh/user/lib/python3.10/multiprocessing/connection.py\", line 76, in arbitrary_address\n",
      "    return tempfile.mktemp(prefix='listener-', dir=util.get_temp_dir())\n",
      "OSError: [Errno 28] No space left on device: '/tmp/pymp-zf9rd7bi'\n",
      "  File \"/opt/tljh/user/lib/python3.10/multiprocessing/util.py\", line 146, in get_temp_dir\n",
      "    tempdir = tempfile.mkdtemp(prefix='pymp-')\n",
      "  File \"/opt/tljh/user/lib/python3.10/tempfile.py\", line 384, in mkdtemp\n",
      "    _os.mkdir(file, 0o700)\n",
      "OSError: [Errno 28] No space left on device: '/tmp/pymp-lbewnotd'\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/tljh/user/lib/python3.10/multiprocessing/queues.py\", line 244, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/opt/tljh/user/lib/python3.10/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/home/jupyter-iec_roadquality/.local/lib/python3.10/site-packages/torch/multiprocessing/reductions.py\", line 429, in reduce_storage\n",
      "    df = multiprocessing.reduction.DupFd(fd)\n",
      "  File \"/opt/tljh/user/lib/python3.10/multiprocessing/reduction.py\", line 198, in DupFd\n",
      "    return resource_sharer.DupFd(fd)\n",
      "  File \"/opt/tljh/user/lib/python3.10/multiprocessing/resource_sharer.py\", line 53, in __init__\n",
      "    self._id = _resource_sharer.register(send, close)\n",
      "  File \"/opt/tljh/user/lib/python3.10/multiprocessing/resource_sharer.py\", line 76, in register\n",
      "    self._start()\n",
      "  File \"/opt/tljh/user/lib/python3.10/multiprocessing/resource_sharer.py\", line 126, in _start\n",
      "    self._listener = Listener(authkey=process.current_process().authkey)\n",
      "  File \"/opt/tljh/user/lib/python3.10/multiprocessing/connection.py\", line 442, in __init__\n",
      "    address = address or arbitrary_address(family)\n",
      "  File \"/opt/tljh/user/lib/python3.10/multiprocessing/connection.py\", line 76, in arbitrary_address\n",
      "    return tempfile.mktemp(prefix='listener-', dir=util.get_temp_dir())\n",
      "  File \"/opt/tljh/user/lib/python3.10/multiprocessing/util.py\", line 146, in get_temp_dir\n",
      "    tempdir = tempfile.mkdtemp(prefix='pymp-')\n",
      "  File \"/opt/tljh/user/lib/python3.10/tempfile.py\", line 384, in mkdtemp\n",
      "    _os.mkdir(file, 0o700)\n",
      "OSError: [Errno 28] No space left on device: '/tmp/pymp-nyhyw5n3'\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/tljh/user/lib/python3.10/multiprocessing/queues.py\", line 244, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/opt/tljh/user/lib/python3.10/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/home/jupyter-iec_roadquality/.local/lib/python3.10/site-packages/torch/multiprocessing/reductions.py\", line 429, in reduce_storage\n",
      "    df = multiprocessing.reduction.DupFd(fd)\n",
      "  File \"/opt/tljh/user/lib/python3.10/multiprocessing/reduction.py\", line 198, in DupFd\n",
      "    return resource_sharer.DupFd(fd)\n",
      "  File \"/opt/tljh/user/lib/python3.10/multiprocessing/resource_sharer.py\", line 53, in __init__\n",
      "    self._id = _resource_sharer.register(send, close)\n",
      "  File \"/opt/tljh/user/lib/python3.10/multiprocessing/resource_sharer.py\", line 76, in register\n",
      "    self._start()\n",
      "  File \"/opt/tljh/user/lib/python3.10/multiprocessing/resource_sharer.py\", line 126, in _start\n",
      "    self._listener = Listener(authkey=process.current_process().authkey)\n",
      "  File \"/opt/tljh/user/lib/python3.10/multiprocessing/connection.py\", line 442, in __init__\n",
      "    address = address or arbitrary_address(family)\n",
      "  File \"/opt/tljh/user/lib/python3.10/multiprocessing/connection.py\", line 76, in arbitrary_address\n",
      "    return tempfile.mktemp(prefix='listener-', dir=util.get_temp_dir())\n",
      "  File \"/opt/tljh/user/lib/python3.10/multiprocessing/util.py\", line 146, in get_temp_dir\n",
      "    tempdir = tempfile.mkdtemp(prefix='pymp-')\n",
      "  File \"/opt/tljh/user/lib/python3.10/tempfile.py\", line 384, in mkdtemp\n",
      "    _os.mkdir(file, 0o700)\n",
      "OSError: [Errno 28] No space left on device: '/tmp/pymp-gdpfthi9'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "alphas = [0.3, 0.5, 0.7]\n",
    "temperature = 20\n",
    "classes = list(range(100))\n",
    "transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                             std=[0.2023, 0.1994, 0.2010])\n",
    "    ])\n",
    "_, _, _, trainloader, validationloader, testloader = load_cifar100(batch_size, transform)\n",
    "target_class = (0,)  # Target specific classes\n",
    "mode = 'probability'\n",
    "percent_nodes_for_targets = 0.1\n",
    "start_attack = 0\n",
    "num_to_assign = None\n",
    "node_sep_probability = [0.01, 0.03, 0.05]\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "for alpha in alphas:\n",
    "    for prob in node_sep_probability:\n",
    "        print(f'====----== Alpha = {alpha}, prob = {prob} =========')\n",
    "        output_path = f'../output/EfficentNetB4-EfficentNetB4-CIFAR100/neuron-seperation/NS_alpha{alpha}-percent-nodes{prob}.json'\n",
    "    \n",
    "        # Teacher Model\n",
    "        dropout_layer = NodeSepDropoutLayer(0.5, mode, percent_nodes_for_targets, prob, num_to_assign)\n",
    "        teacher_model = TeacherNet(dropout_layer).to(device)\n",
    "        teacher_wrapper = NetWrapper_T(teacher_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "        teacher_model.load_state_dict(torch.load(os.path.join(f\"../output/EfficentNetB4-EfficentNetB4-CIFAR100/neuron-seperation/NS-teacher_model_percent-nodes{prob}.pth\")))\n",
    "        teacher_model.eval()\n",
    "        \n",
    "\n",
    "        # Student Model\n",
    "        student_dropout = nn.Dropout(p=0.5)\n",
    "        student_model = StudentNet().to(device)\n",
    "        student_optimizer = optim.Adam(student_model.parameters(), lr=1e-3)\n",
    "\n",
    "    \n",
    "        # Train Student\n",
    "        student_model.train()\n",
    "        best_val_accuracy = 0\n",
    "        patience = 5  \n",
    "        counter = 0 \n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            running_loss = 0.0\n",
    "            for inputs, labels in trainloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                #print (labels)\n",
    "                student_optimizer.zero_grad()\n",
    "                with torch.no_grad():\n",
    "                    teacher_outputs = teacher_model(inputs)\n",
    "                    #print(teacher_outputs)\n",
    "                student_outputs = student_model(inputs)\n",
    "                #print(student_outputs)\n",
    "                loss = distillation_loss(student_outputs, teacher_outputs, labels, temperature, alpha)\n",
    "                loss.backward()\n",
    "                student_optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "        \n",
    "            # Validation loop for metrics\n",
    "            student_model.eval()\n",
    "            val_preds = []\n",
    "            val_labels = []\n",
    "            with torch.no_grad():\n",
    "                for val_inputs, val_targets in validationloader:\n",
    "                    val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "                    val_outputs = student_model(val_inputs)\n",
    "                    _, preds = torch.max(val_outputs, 1)\n",
    "                    val_preds.extend(preds.cpu().numpy())\n",
    "                    val_labels.extend(val_targets.cpu().numpy())\n",
    "        \n",
    "            # Calculate metrics\n",
    "            train_loss_avg = running_loss / len(trainloader)\n",
    "            val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "            val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "        \n",
    "            print(f\"Epoch [{epoch + 1}/{epochs}] - Loss: {train_loss_avg:.4f}, \"\n",
    "                  f\"Validation Accuracy: {val_accuracy:.4f}, Validation F1 Score: {val_f1:.4f}\")\n",
    "        \n",
    "            # --- EARLY STOPPING ---\n",
    "            if val_accuracy > best_val_accuracy:\n",
    "                best_val_accuracy = val_accuracy\n",
    "                counter = 0  # Reset counter nếu có cải thiện\n",
    "            else:\n",
    "                counter += 1\n",
    "                print(f\"EarlyStopping counter: {counter} out of {patience}\")\n",
    "                if counter >= patience:\n",
    "                    print(\"Early stopping triggered.\")\n",
    "                    break\n",
    "            # ----------------------\n",
    "        \n",
    "            student_model.train()\n",
    "\n",
    "        # Evaluate Student Model\n",
    "        student_wrapper = NetWrapper_T(student_model, nn.CrossEntropyLoss(), optim.Adam, [1e-3])\n",
    "        accuracy, _, conf_matrix, per_class_acc, per_class_precision = student_wrapper.evaluate(testloader, num_classes = 100)\n",
    "\n",
    "        write_to_json(\n",
    "            output_path, \n",
    "            'distillation', \n",
    "            student_wrapper, \n",
    "            accuracy, \n",
    "            conf_matrix, \n",
    "            per_class_acc, \n",
    "            per_class_precision, \n",
    "            classes\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab81c4d-09ed-4208-a5f3-90216b04fe35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
